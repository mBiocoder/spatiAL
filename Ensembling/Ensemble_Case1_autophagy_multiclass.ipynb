{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c53e02e",
   "metadata": {},
   "source": [
    "# Ensemble to retrain the de novo model with 5 different seeds via random subset on a different subset of each class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3b40e",
   "metadata": {},
   "source": [
    "<b> What is our goal? <b>\n",
    "\n",
    "The main goal is to develop a model that has meaningful uncertainty, meaning the uncertainty is low for known and biologically uninteresting classes, but high for unknown and ideally biologically interesting classes. Our hope would be that this new model learns something the original classifier (autophagy_2_1 from SPACRSpy) did not, thereby identifying something new.\n",
    "The way to test this for the multi-class classifier is by leaving out different biological conditions during training and then checking uncertainty on them as well as by evaluate the new model with screening data, plotting its 8th layer in UMAP and investigating the classifcation scores between the old and new models.\n",
    "\n",
    "<b> What have we done so far? <b>\n",
    "\n",
    "So far we got for Case 1 the 8th layer activations plotted in a UMAP and identified screening hits. Prior to excising these cells, we need to ensure we are certain about which cells to excise and therefore we want to try different ensemble approaches and get a list of cell ids and their respective slide numbers which seem to overlap across the emsembling process and these cells we want to excise. This way we try to correct for the fact that our screening hits may contain technical artifacts. In other words, if we were to excise these 72 screening hits which are potentially contaminated with technical artifacts, we would see no enrichment of any gene. Thus we want to be computationally as confident as possible that these are actually interesting screening hits, then if there is nothing enriched, we at least learn something about the computational approach we used which means our model identifies some technical artifact very confidently. Within a single slide we expect batch effect. We found 72 screening hits in a subset of 7200 cells and a single slide has approx. 300000 cells and thus we expect approx. 3000 screening hits in total.\n",
    "\n",
    "<b> What data do we have now? <b>\n",
    "\n",
    "1. Stimulated 14h (or 16h) -> labelled as 0\n",
    "2. Unstimulated -> labelled as 1\n",
    "3. ATG5 KO (stimulated but that doesn’t matter, this KO supersedes the stim status [probably looks like unstimulated data]) -> labelled as 2\n",
    "4. Stimulated timecourse data -> labelled as 3\n",
    "5. EI24 KO timecourse data (more similar to unstim) -> labelled as 4\n",
    "6. Screening data (similar to stim) -> labelled as 5\n",
    "\n",
    "\n",
    "<b> What are we doing in this section? <b>\n",
    "\n",
    "Here we retrain our de novo model on a different subset of each class 5 times via random subset. Specifically, for each run, we randomly sample 75,000 instances per class (e.g., 0 and 2 in the first case), train the de novo classifier on these subsets and save the resulting models. Repeat this for five iterations, ensuring the random subsets differ in each run. After training, we evaluate the models on the test set and compare performance across the different iterations. Then, we investigate the uncertainty scores of the models, focusing on how they classify both known and unknown biological classes.\n",
    "We do this all for Case 1(0,2 for training, and all other classes in test).\n",
    "\n",
    "<b> Why do we do this? <b>\n",
    "\n",
    "We run the ensembling to become more certain about if the screening hits we see are worth excising or not. Specifically, it allows us to explore the variability in classification and uncertainty across different splits of the data. This process can help identify patterns that a single de novo model run might have missed, especially in the context of uncertainty. We evaluate on how well the de novo model does on the EI24 knockout.\n",
    "Since El24 looks more distinctly different from both and thus our best positive control; if we can detect this based on uncertainty then we can detect novel biology!\n",
    "We want the UMAP on the test set to show all biological classes and also we want the images visualized of the screening hits in case there is something visually interesting.\n",
    "Also we need to cross reference with the cells we have already excised from autophagy_2_1 model as hits since that binary model can recognize anything which is unstim as a hit in the screen and thus we have to filter our resulting cells for those which hasn’t already been excised. \n",
    "\n",
    "<b> What to do from here? <b>\n",
    "\n",
    "1. We could also try the LOF as a score. By applying LOF we can gain an additional layer of confidence in identifying truly novel phenotypes. LOF helps differentiate between points that are genuine anomalies and those that are within expected variability. \n",
    "2. After training the five models, we could ensemble them by averaging their predictions or using a majority vote for classification. This will help smooth out individual model variability and may highlight outliers or new patterns.\n",
    "3. We want to run Case 8 (0,2,4|test everything) as a positive control.\n",
    "4. We could run uncertainty on 3 or 4 classes (our other cases) and have a statistic on how well we do as we increase number of classes and ideally find a nice list of cell ids to excise which contain a novel phenotype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadc1b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-intermediate-layer-getter in /usr/local/lib/python3.10/dist-packages (0.1.post1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: leidenalg in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
      "Requirement already satisfied: igraph<0.12,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from leidenalg) (0.11.8)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph<0.12,>=0.10.0->leidenalg) (1.7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scanpy==1.9.6 in /usr/local/lib/python3.10/dist-packages (1.9.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (23.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.23.5)\n",
      "Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.0.0)\n",
      "Requirement already satisfied: umap-learn>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.5.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (4.65.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.2.0)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (8.4.0)\n",
      "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.14.4)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.7.1)\n",
      "Requirement already satisfied: h5py>=3 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.9.0)\n",
      "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.1)\n",
      "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: pandas!=2.1.2,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.5.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.10.1)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.5.6)\n",
      "Requirement already satisfied: anndata>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.11.0)\n",
      "Requirement already satisfied: seaborn!=0.13.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.12.2)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scanpy==1.9.6) (1.9.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scanpy==1.9.6) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (4.39.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (1.4.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.41.0->scanpy==1.9.6) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.2,>=1.1.1->scanpy==1.9.6) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->scanpy==1.9.6) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy==1.9.6) (3.1.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.3.10->scanpy==1.9.6) (0.5.13)\n",
      "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy==1.9.6) (0.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: anndata in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
      "Requirement already satisfied: h5py>=3.6 in /usr/local/lib/python3.10/dist-packages (from anndata) (3.9.0)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.9.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.23.5)\n",
      "Requirement already satisfied: pandas!=2.1.0rc0,!=2.1.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from anndata) (23.1)\n",
      "Requirement already satisfied: scipy>1.8 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.10.1)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata) (8.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2023.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (65.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.6.0)\n",
      "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (8.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.15.0)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.1.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.15.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.38)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.0->watermark) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-intermediate-layer-getter\n",
    "!pip install umap-learn\n",
    "!pip install leidenalg\n",
    "!pip install scanpy==1.9.6\n",
    "!pip install anndata umap-learn\n",
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e247accf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nexusformat\n",
      "  Downloading nexusformat-1.0.6-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdf5plugin\n",
      "  Downloading hdf5plugin-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.6 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nexusformat) (1.10.1)\n",
      "Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.10/dist-packages (from nexusformat) (3.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nexusformat) (1.23.5)\n",
      "Installing collected packages: hdf5plugin, nexusformat\n",
      "Successfully installed hdf5plugin-5.0.0 nexusformat-1.0.6\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nexusformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c04ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%load_ext watermark\n",
    " \n",
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "import sys\n",
    "import seaborn as sn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n",
    "import umap\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "import h5py\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sparcscore.ml.datasets import HDF5SingleCellDataset\n",
    "# from sparcscore.pipeline.project import TimecourseProject, Project\n",
    "# from sparcscore.pipeline.workflows import MultithreadedWGATimecourseSegmentation, WGATimecourseSegmentation, MultithreadedCytosolCellposeTimecourseSegmentation, ShardedWGASegmentation, ShardedDAPISegmentationCellpose, WGASegmentation, DAPISegmentationCellpose\n",
    "from sparcscore.pipeline.extraction import HDF5CellExtraction, TimecourseHDF5CellExtraction\n",
    "from sparcscore.pipeline.classification import MLClusterClassifier\n",
    "from sparcscore.ml.pretrained_models import autophagy_classifier2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f9b73",
   "metadata": {},
   "source": [
    "## I. Load in full data and big and small test sets <a class=\"anchor\" id=\"test-set\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hdf5_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_A002/single_cells.h5', \n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_B004/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_D001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_F003/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_H002/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_K001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.X_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.X_stim_Cr203_filtered.h5'],\n",
    "    dir_labels=[4, 4, 4, 5, 5, 5, 5, 5, 5, 3, 3, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "113e8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "   \n",
    "class HDF5SingleCellDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class for handling SPARCSpy single cell datasets stored in HDF5 files.\n",
    "\n",
    "    This class provides a convenient interface for SPARCSpy formated hdf5 files containing single cell datasets. It supports loading data\n",
    "    from multiple hdf5 files within specified directories, applying transformations on the data, and returning\n",
    "    the required information, such as label or id, along with the single cell data.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    root_dir : str\n",
    "        Root directory where the hdf5 files are located.\n",
    "    dir_labels : list of int\n",
    "        List of labels corresponding to the directories in dir_list.\n",
    "    dir_list : list of str\n",
    "        List of path(s) where the hdf5 files are stored. Supports specifying a path to a specific hdf5 file or directory\n",
    "        containing hdf5 files.\n",
    "    transform : callable, optional\n",
    "        A optional user-defined function to apply transformations to the data. Default is None.\n",
    "    max_level : int, optional\n",
    "        Maximum levels of directory to search for hdf5 files. Default is 5.\n",
    "    return_id : bool, optional\n",
    "        Whether to return the index of the cell with the data. Default is False.\n",
    "    return_fake_id : bool, optional\n",
    "        Whether to return a fake index (0) with the data. Default is False.\n",
    "    select_channel : int, optional\n",
    "        Specify a specific channel to select from the data. Default is None, which returns all channels.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    add_hdf_to_index(current_label, path)\n",
    "        Adds single cell data from the hdf5 file located at ‘path’ with the specified ‘current_label’ to the index.\n",
    "    scan_directory(path, current_label, levels_left)\n",
    "        Scans directories for hdf5 files and adds their data to the index with the specified ‘current_label’.\n",
    "    stats()\n",
    "        Prints dataset statistics including total count and count per label.\n",
    "    len()\n",
    "        Returns the total number of single cells in the dataset.\n",
    "    getitem(idx)\n",
    "        Returns the data, label, and optional id/fake_id of the single cell specified by the index ‘idx’.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> hdf5_data = HDF5SingleCellDataset(dir_list=[‘data1.hdf5’, ‘data2.hdf5’],\n",
    "    dir_labels=[0, 1],\n",
    "    root_dir=‘/path/to/data’,\n",
    "    transform=None,\n",
    "    return_id=True)\n",
    "    >>> len(hdf5_data)\n",
    "    2000\n",
    "    >>> sample = hdf5_data[0]\n",
    "    >>> sample[0].shape\n",
    "    torch.Size([1, 128, 128])\n",
    "    >>> sample[1]\n",
    "    tensor(0)\n",
    "    >>> sample[2]\n",
    "    tensor(0)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    HDF_FILETYPES = [\"hdf\", \"hf\", \"h5\", \"hdf5\"]\n",
    "    def __init__(self, dir_list, \n",
    "                 dir_labels, \n",
    "                 root_dir, \n",
    "                 max_level=5, \n",
    "                 transform=None, \n",
    "                 return_id=False, \n",
    "                 return_fake_id=False,\n",
    "                 select_channel=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.dir_labels = dir_labels\n",
    "        self.dir_list = dir_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.handle_list = []\n",
    "        self.data_locator = []\n",
    "        \n",
    "        self.select_channel = select_channel\n",
    "        \n",
    "        # scan all directoreis\n",
    "        for i, directory in enumerate(dir_list):\n",
    "            path = os.path.join(self.root_dir, directory)  \n",
    "            current_label = self.dir_labels[i]\n",
    "\n",
    "            #check if \"directory\" is a path to specific hdf5\n",
    "            filetype = directory.split(\".\")[-1]\n",
    "            filename = directory.split(\".\")[0]\n",
    "                \n",
    "            if filetype in self.HDF_FILETYPES:\n",
    "                self.add_hdf_to_index(current_label, directory)\n",
    "\n",
    "            else:\n",
    "                # recursively scan for files\n",
    "                self.scan_directory(path, current_label, max_level)\n",
    "        \n",
    "        # print dataset stats at the end\n",
    "        \n",
    "        self.return_id = return_id\n",
    "        self.return_fake_id = return_fake_id\n",
    "        self.stats()\n",
    " \n",
    "        \n",
    "    def add_hdf_to_index(self, current_label, path):       \n",
    "        try:\n",
    "            input_hdf = h5py.File(path, 'r')\n",
    "            index_handle = input_hdf.get('single_cell_index')\n",
    "\n",
    "            handle_id = len(self.handle_list)\n",
    "            self.handle_list.append(input_hdf.get('single_cell_data'))\n",
    "\n",
    "            for row in index_handle:\n",
    "                self.data_locator.append([current_label, handle_id]+list(row))      \n",
    "        except:\n",
    "            return\n",
    "        \n",
    "    def scan_directory(self, path, current_label, levels_left):\n",
    "        \n",
    "        # iterates over all files and folders in a directory\n",
    "        # hdf5 files are added to the index\n",
    "        # subfolders are recursively scanned\n",
    "        \n",
    "        if levels_left > 0:\n",
    "            \n",
    "            # get files and directories at current level\n",
    "            input_list = os.listdir(path)\n",
    "            current_level_directories = [os.path.join(path, name) for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "\n",
    "            current_level_files = [ name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]\n",
    "                        \n",
    "            for i, file in enumerate(current_level_files):\n",
    "                filetype = file.split(\".\")[-1]\n",
    "                filename = file.split(\".\")[0]\n",
    "                \n",
    "                if filetype in self.HDF_FILETYPES:\n",
    "                    \n",
    "                    self.add_hdf_to_index(current_label, os.path.join(path, file))\n",
    "                    \n",
    "            # recursively scan subdirectories        \n",
    "            for subdirectory in current_level_directories:\n",
    "                self.scan_directory(subdirectory, current_label, levels_left-1)\n",
    "            \n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def stats(self):\n",
    "    \n",
    "        labels = [el[0] for el in self.data_locator]\n",
    "        \n",
    "        print(\"Total: {}\".format(len(labels)))\n",
    "        \n",
    "        for l in set(labels):\n",
    "            print(\"{}: {}\".format(l,labels.count(l)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_locator)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # get the label, filename and directory for the current dataset\n",
    "        data_info = self.data_locator[idx]\n",
    "        \n",
    "        if self.select_channel is not None:\n",
    "            cell_tensor = self.handle_list[data_info[1]][data_info[2], self.select_channel]\n",
    "            t = torch.from_numpy(cell_tensor)\n",
    "            t = torch.unsqueeze(t,0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            cell_tensor = self.handle_list[data_info[1]][data_info[2]]\n",
    "            t = torch.from_numpy(cell_tensor)\n",
    "            \n",
    "        t = t.float()     \n",
    "        \n",
    "        if self.transform:\n",
    "            t = self.transform(t)\n",
    "        \"\"\"  \n",
    "        if not list(t.shape) == list(torch.Size([1,128,128])):\n",
    "            t = torch.zeros((1,128,128))\n",
    "        \"\"\"      \n",
    "        if self.return_id and self.return_fake_id:\n",
    "            raise ValueError(\"either return_id or return_fake_id should be set\")\n",
    "            \n",
    "        if self.return_id:\n",
    "            \n",
    "            ids = int(data_info[3])\n",
    "            sample = (t, torch.tensor(data_info[0]), torch.tensor(ids))\n",
    "        elif self.return_fake_id:\n",
    "            \n",
    "            sample = (t, torch.tensor(data_info[0]), torch.tensor(0))\n",
    "        else:\n",
    "            sample = (t, torch.tensor(data_info[0]))\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e50f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 861724\n",
      "0: 100000\n",
      "1: 100000\n",
      "2: 100000\n",
      "3: 100000\n",
      "4: 40280\n",
      "5: 421444\n"
     ]
    }
   ],
   "source": [
    "full_testset_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_A002/single_cells.h5', \n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_Cr203_filtered.h5'],\n",
    "    dir_labels=[4, 5, 3, 0, 1, 2], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1e15e",
   "metadata": {},
   "source": [
    "From full_hdf5_data only the first file is used for building the independant, full and unbalanced testset. For the full unbalanced trainset we take all other files except the first one which was used for creating the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73814336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 2866498\n",
      "0: 400000\n",
      "1: 100000\n",
      "2: 200000\n",
      "3: 100000\n",
      "4: 94851\n",
      "5: 1971647\n"
     ]
    }
   ],
   "source": [
    "case1_full_trainset_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_B004/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_D001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_F003/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_H002/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_K001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.X_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.X_stim_Cr203_filtered.h5'],\n",
    "    dir_labels=[4, 4, 5, 5, 5, 5, 5, 3, 0, 0, 0, 0, 1, 2, 2], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e77849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def undersample_dataset(dataset, target_classes, n_instances=None, seed=None):\n",
    "    \"\"\"\n",
    "    Undersamples the dataset so target_classes have equal number of instances.\n",
    "    If n_instances is set, each class will have n_instances samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: PyTorch Dataset object containing the features (e.g., HDF5SingleCellDataset)\n",
    "    - target_classes: the list of classes to undersample (e.g., [0, 2] for training)\n",
    "    - n_instances: number of samples per class (None means use minimum of class sizes)\n",
    "    - seed: random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - undersampled_dataset: the undersampled dataset (list of samples)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    undersampled_data = []\n",
    "    \n",
    "    for cls in target_classes:\n",
    "        class_indices = [i for i, (_, label) in enumerate(dataset) if label == cls]\n",
    "        if n_instances is None:\n",
    "            n_instances = len(class_indices)\n",
    "        \n",
    "        # Randomly sample n_instances for each class\n",
    "        sampled_indices = np.random.choice(class_indices, n_instances, replace=False)\n",
    "        undersampled_data.extend([dataset[i] for i in sampled_indices])\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    undersampled_data = shuffle(undersampled_data, random_state=seed)\n",
    "    return undersampled_data\n",
    "\n",
    "# Function to create balanced testset for classes 0-5\n",
    "def create_balanced_testset(dataset, target_classes, n_instances_per_class):\n",
    "    \"\"\"\n",
    "    Create a balanced testset with n_instances_per_class for each class in target_classes.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: HDF5SingleCellDataset\n",
    "    - target_classes: list of classes \n",
    "    - n_instances_per_class: number of instances to sample per class\n",
    "    \n",
    "    Returns:\n",
    "    - balanced_testset: list of samples with balanced instances per class\n",
    "    \"\"\"\n",
    "    balanced_data = []\n",
    "    \n",
    "    for cls in target_classes:\n",
    "        print(cls)\n",
    "        class_indices = [i for i, (_, label) in enumerate(dataset) if label == cls]\n",
    "        # Randomly sample n_instances_per_class for each class\n",
    "        sampled_indices = np.random.choice(class_indices, n_instances_per_class, replace=False)\n",
    "        balanced_data.extend([dataset[i] for i in sampled_indices])\n",
    "    \n",
    "    # Shuffle balanced testset\n",
    "    balanced_data = shuffle(balanced_data, random_state=42)  \n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfcbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, labels, save_path):\n",
    "    # stack the data into single tenso\n",
    "    images_tensor = torch.stack([dataset[i][0] for i in range(len(dataset))])\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    torch.save((images_tensor, labels_tensor), save_path)\n",
    "    print(f\"Dataset saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bcfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(save_path, batch_size):\n",
    "    images_tensor, labels_tensor = torch.load(save_path)\n",
    "    \n",
    "    # Create a TensorDataset from the loaded tensors\n",
    "    dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f\"Loaded dataset from {save_path}\")\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334b243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42, 101, 202, 303, 404]   # Different seeds for ensembling\n",
    "batch_size = 256                    # Batch size for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create balanced testset for classes 0-5 (fixed across all training processes)\n",
    "n_test_instances_per_class = 2000    # Test instances for each class (0-5)\n",
    "\n",
    "target_test_classes = [0, 1, 2, 3, 4, 5]\n",
    "balanced_testset = create_balanced_testset(full_testset_data, target_test_classes, n_test_instances_per_class)\n",
    "\n",
    "# Create test DataLoader (shared for all training processes)\n",
    "test_data_loader = DataLoader(balanced_testset, batch_size=batch_size, shuffle=True, num_workers=14, pin_memory=True)\n",
    "\n",
    "# Print test set class distribution\n",
    "test_labels = [label for _, label in balanced_testset]\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "print(f\"Test set class distribution (balanced): {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the balanced testset and undersampled training sets\n",
    "balanced_test_labels = [label for _, label in balanced_testset]  # Extracting labels\n",
    "save_dataset(balanced_testset, balanced_test_labels, \"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create 5 different training sets with different seeds (for classes 0 and 2)\n",
    "n_train_instances_per_class = 100000 # Training instances for each class (0 and 2)\n",
    "train_loaders = []\n",
    "target_train_classes = [0, 2]  # We only use classes 0 and 2 for training\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"seed \" + str(seed))\n",
    "    undersampled_trainset = undersample_dataset(case1_full_trainset_data, target_train_classes, \n",
    "                                                n_instances=n_train_instances_per_class, seed=seed)\n",
    "    \n",
    "    # Create DataLoader for each seed\n",
    "    train_loader = DataLoader(undersampled_trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=14, pin_memory=True)\n",
    "    train_loaders.append(train_loader)\n",
    "\n",
    "    # Print train set class distribution\n",
    "    train_labels = [label for _, label in undersampled_trainset]\n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train set class distribution (seed {seed}): {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540bb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trainset, train_labels) in enumerate(zip(train_loaders, seeds)):\n",
    "    save_dataset(trainset.dataset, train_labels, f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/undersampled_trainset_seed_{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3bbfb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the balanced testset\n",
    "test_data_loader = load_dataset(\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a602d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 215040\n",
      "-rw-rw---- 1 di93quv pn36po 65554048 Sep 17 18:26  trainset_0_seed_42.h5\n",
      "-rw-rw---- 1 di93quv pn36po 65554048 Sep 17 18:27  trainset_2_seed_42.h5\n",
      "-rw-rw---- 1 di93quv pn36po 82019584 Sep 29 22:31 'trainset_[0, 2]_seed_42.h5'\n",
      "-rw-rw---- 1 di93quv pn36po    23113 Sep 29 22:31  trainset_indices_42.pkl\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_0.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_1.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_2.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_3.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_4.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -l /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1_small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dad1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load undersampled training sets\n",
    "train_loaders = []\n",
    "for i in range(len(seeds)):\n",
    "    train_loader = load_dataset(f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1_small/undersampled_trainset_seed_{i}.pt\", batch_size)\n",
    "    train_loaders.append(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed28ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFACAYAAABN45K5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACRVUlEQVR4nO19f7QsV1Xmt8+p7vvjvYSQiCEgSQyEECFoQGTAUQZGDCzNRESIgAoIGhWMCMzKMIDKAkUFg4ARJcwijIg4CDqIQERGFAMK6CSghCSEQHAkCMFI3o/b3XXOnj/2j3Oquu99t/Pr3fte7bVebm7f6qrq6jpf7f3tb+9NzMwYbLDBBlvCwuE+gcEGG2z32QAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbABx3oV122WU47rjjDvdpHJH2n/7Tf8Lznve827WP4fvZvh11wPGMZzwDROT/TjjhBDzucY/DJz/5yaX280u/9Ev4tm/7tjvnJCv7/Oc/DyLClVdeeacf63AaEeFP/uRPDvdpHNJ++Zd/GY985COxvr5+VIPMUQccAPC4xz0OX/rSl/ClL30JH/zgB9E0Db7/+7//cJ/WYLvAptMpnvSkJ+Gnf/qnD/epHFY7KoFjZWUF97znPXHPe94T3/Zt34b/9t/+G774xS/iK1/5im9z0UUX4f73vz/W19dx2mmn4aUvfSlmsxkAcWlf9rKX4aqrrnLP5bLLLgMA3HLLLbjgggtw4oknYnV1FQ960IPwnve8p3P8yy+/HGeeeSb27t3rILZd+9CHPgQiwuWXX46zzz4ba2treMxjHoN//dd/xfve9z6ceeaZOPbYY/HUpz4VBw4c8Pe9//3vx3/8j/8Rxx13HE444QR8//d/P66//vrOvj/ykY/g277t27C6uopv//Zvx5/8yZ/MeTv/+I//iMc//vHYu3cvTjzxRPzoj/4ovvrVr277/G+L3XzzzXjKU56Ce9/73lhfX8dZZ52FP/iDP5jbrm1bPPe5z8Xd7nY3fMM3fANe+tKXoq7hnEwmeOELX4h73/ve2LNnDx7+8IfjQx/60FLn8rKXvQw///M/j7POOuv2fqxdbUclcNS2b98+vPWtb8X97nc/nHDCCf76Mcccg8suuwyf/vSn8drXvhaXXnopXvOa1wAAzj//fLzgBS/AAx/4QPdczj//fOSc8fjHPx5XXHEF3vrWt+LTn/40fvVXfxUxRt/vgQMH8OpXvxq/93u/h7/+67/GjTfeiBe+8IVLn/cv/dIv4bd+67fwkY98BF/84hfx5Cc/Gb/5m7+Jt73tbfizP/sz/Pmf/zle//rX+/b79+/H85//fHziE5/ABz/4QYQQ8IQnPAE5ZwDA17/+dZx77rk466yz8A//8A94+ctfjosuuqhzzFtuuQWPecxjcPbZZ+MTn/gE3v/+9+PLX/4ynvzkJy99/svYxsYGHvrQh+LP/uzP8I//+I/4yZ/8Sfzoj/4oPvaxj3W2e8tb3oKmafCxj30Mr33ta3HxxRfjTW96k//9uc99Lj760Y/i7W9/Oz75yU/iSU96Eh73uMfhuuuuu1PP/4g0Psrs6U9/OscYec+ePbxnzx4GwCeddBL//d///Zbve9WrXsUPfehD/fdf/MVf5G/91m/tbHP55ZdzCIGvueaahft485vfzAD4s5/9rL92ySWX8IknnrjpcW+44QYGwP/3//5fZmb+y7/8SwbAf/EXf+HbvPKVr2QAfP311/trF1xwAZ9zzjmb7vcrX/kKA+BPfepTzMz8hje8gU844QQ+ePCgb3PppZd2jv3yl7+cv/d7v7ezny9+8YsMYNPPvF0DwH/8x3+87e2/7/u+j1/wghf474961KP4zDPP5Jyzv3bRRRfxmWeeyczMX/jCFzjGyP/v//2/zn7+83/+z/yiF72ImeX7udvd7rat4y+z7ZFoR6XH8ehHPxpXXnklrrzySnzsYx/DOeecg8c//vH4whe+4Nv84R/+Ib7zO78T97znPbF371685CUvwY033rjlfq+88kp80zd9E+5///tvus36+jrue9/7+u8nnXQS/vVf/3Xpz/DgBz/Y///EE0/0kKp+rd7vddddh6c85Sk47bTTcOyxx+LUU08FAP9M11xzDR784AdjdXXV3/Md3/EdnWNeddVV+Mu//Evs3bvX/z3gAQ8AgLmwx6ze9qd+6qeW/pwAkFLCy1/+cpx11lk4/vjjsXfvXlx++eVz38d/+A//AUTkvz/iEY/Addddh5QSPvWpTyGlhPvf//6dc/qrv/qrTc99sM2tOdwncDhsz549uN/97ue/v+lNb8Ld7nY3XHrppXjFK16Bj370o3ja056Gl73sZTjnnHNwt7vdDW9/+9vxG7/xG1vud21t7ZDHHo1Gnd+JqBOHb9fq/RDRwv1aGAIA5557Lk455RRceumluNe97oWcMx70oAdhOp1u+5j79u3Dueeei1/7tV+b+9tJJ5208D01P3Lsscdu+1i1vepVr8JrX/ta/OZv/ibOOuss7NmzB8973vOWPvcYI/7+7/++EzoCAm6DLWdHJXD0jYgQQsDBgwcBCEl4yimn4MUvfrFvU3sjADAej5FS6rz24Ac/GP/8z/+Ma6+9dkuv4662m2++Gddccw0uvfRSfNd3fRcA4G/+5m8625xxxhl461vfislkgpWVFQDAxz/+8c42D3nIQ/DOd74Tp556Kppme7dODdC31a644gqcd955+JEf+REAQM4Z1157Lb7lW76ls93f/d3fdX7/27/9W5x++umIMeLss89GSgn/+q//6tdgsNtuR2WoMplMcNNNN+Gmm27C1VdfjZ/92Z/1pykAnH766bjxxhvx9re/Hddffz1e97rX4Y//+I87+zj11FNxww034Morr8RXv/pVTCYTPOpRj8J3f/d344lPfCI+8IEP4IYbbsD73vc+vP/97z8cH9Pt7ne/O0444QS88Y1vxGc/+1n8n//zf/D85z+/s81Tn/pU5Jzxkz/5k7j66qtx+eWX49WvfjUAuPv/nOc8B1/72tfwlKc8BR//+Mdx/fXX4/LLL8czn/nMORC9LWbXs/63f/9+nH766fjABz6Aj3zkI7j66qtxwQUX4Mtf/vLc+2+88UY8//nPxzXXXIM/+IM/wOtf/3r83M/9HADg/ve/P572tKfhx37sx/Cud70LN9xwAz72sY/hla98Jf7sz/5s2+d444034sorr8SNN96IlJKf5759+273599VdrhJlrvanv70pzMA/3fMMcfwwx72MP6jP/qjznb/9b/+Vz7hhBN47969fP755/NrXvOaDhm2sbHBT3ziE/m4445jAPzmN7+ZmZlvvvlmfuYzn8knnHACr66u8oMe9CB+z3vew8yLCbU//uM/5q2+hs3I0X/7t3/zbRbtt0/efuADH+AzzzyTV1ZW+MEPfjB/6EMfmiMkr7jiCn7wgx/M4/GYH/rQh/Lb3vY2BsCf+cxnfJtrr72Wn/CEJ/Bxxx3Ha2tr/IAHPICf97zndUjJ22L1d1L/+/CHP8w333wzn3feebx3717+xm/8Rn7JS17CP/ZjP8bnnXeev/9Rj3oU/8zP/Az/1E/9FB977LF897vfnf/7f//vnfOaTqf8C7/wC3zqqafyaDTik046iZ/whCfwJz/5yU2vY9/694/9+8u//Mvb9fl3mxHz0Kx4sMX2+7//+3jmM5+Jf//3f98WfzPY0WMDxzGY2//8n/8Tp512Gu5973vjqquuwkUXXYQnP/nJA2gMNmcDcAzmdtNNN+EXfuEXcNNNN+Gkk07Ck570JPzyL//y4T6twXagDaHKYIMNtrQdlVmVwQYb7PbZAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba07UjguDMGEN9VQ6KB3TNAGZAh3D/wAz9wuE9j19upp56K3/zN37xd+7gr79Hba3c5cHzlK1/BT//0T+Pkk0/2Ga7nnHMOrrjiCt/mS1/6Eh7/+Mff1ae2Lbvpppvwsz/7szjttNOwsrKC+9znPjj33HPxwQ9+8HCf2p1iNqv2lltuOdyncqfZ5z//+bkZuTvVLrzwQjz0oQ/FysrKYQWZu7x14BOf+ERMp1O85S1vwWmnnYYvf/nL+OAHP4ibb77Zt7nnPe95V5/Wtuzzn/88vvM7vxPHHXccXvWqV+Gss87CbDbD5Zdfjuc85zn4zGc+c7hPcbCjwH78x38cf/d3f4dPfvKTh+0c7lKP45ZbbsGHP/xh/Nqv/Roe/ehH45RTTsF3fMd34EUvehH+y3/5L75d7erb0+Bd73oXHv3oR2N9fR3f+q3fio9+9KOdfV966aW4z33ug/X1dTzhCU/AxRdfjOOOO27L83nTm96EM888E6urq3jAAx6A3/7t395y+5/5mZ8BEeFjH/sYnvjEJ+L+978/HvjAB+L5z38+/vZv/7az7Ve/+lU84QlPwPr6Ok4//XS8+93v9r+llPCsZz0L3/zN34y1tTWcccYZeO1rX9t5v4UQr371q3HSSSfhhBNOwHOe8xzMZjPf5tRTT8Wv/Mqv4Md//MdxzDHH4OSTT8Yb3/jGzn5sIPVxxx2H448/Hueddx4+//nPb/k5t7LLLrsMxx13HN7znvfgjDPOwPr6On7oh34IBw4cwFve8haceuqpuPvd744LL7ywM2vl937v9/Dt3/7tOOaYY3DPe94TT33qU+dGX7773e/G6aefjtXVVTz60Y/GW97yljlv52/+5m/wXd/1XVhbW8N97nMfXHjhhdi/f/9t/jzbseuvvx7nnXceTjzxROzduxcPe9jD8Bd/8Rdz29166614ylOegj179uDe9743Lrnkks7fb7nlFjz72c/GPe5xDxx77LF4zGMeg6uuumqpc3nd616H5zznOZ1xn4fF7spZDLPZjPfu3cvPe97zeGNjY9PtUM37sLkiD3jAA/g973kPX3PNNfxDP/RDfMopp/BsNmNm5r/5m7/hEAK/6lWv4muuuYYvueQSPv744zszMvpzRt761rfySSedxO985zv5c5/7HL/zne/k448/ni+77LKF53TzzTczEfGv/MqvHPJzAuBv+qZv4re97W183XXX8YUXXsh79+7lm2++mZnLfI+Pf/zj/LnPfY7f+ta38vr6Ov/hH/6h7+PpT386H3vssfxTP/VTfPXVV/Of/umf8vr6Or/xjW/0bU455RQ+/vjj+ZJLLuHrrruOX/nKV3IIweegTKdTPvPMM/nHf/zH+ZOf/CR/+tOf5qc+9al8xhln8GQy8ePU80n61p/j8uY3v5lHoxE/9rGP5X/4h3/gv/qrv+ITTjiBv/d7v5ef/OQn8z/90z/xn/7pn/J4POa3v/3tvp//8T/+B7/3ve/l66+/nj/60Y/yIx7xCH784x/vf//c5z7Ho9GIX/jCF/JnPvMZ/oM/+AO+973v3Tn2Zz/7Wd6zZw+/5jWv4WuvvZavuOIKPvvss/kZz3jGIb+Traw/u6ZvV155Jf/O7/wOf+pTn+Jrr72WX/KSl/Dq6ip/4Qtf8G1OOeUUPuaYY/iVr3wlX3PNNfy6172OY4z853/+577N93zP9/C5557LH//4x/naa6/lF7zgBXzCCSf4fbFokPlmtsy2d4bd5QOZ/uiP/ojvfve78+rqKj/ykY/kF73oRXzVVVd1T2oBcLzpTW/yv//TP/0TA+Crr76amZnPP/98/r7v+77OPp72tKdtCRz3ve99+W1ve1vnPS9/+cv5EY94xMLz/ru/+zsGwO9617sO+RkB8Ete8hL/fd++fQyA3/e+9236nuc85zn8xCc+0X9/+tOfzqeccgq3beuvPelJT+Lzzz/ffz/llFP4R37kR/z3nDN/4zd+I7/hDW9gZubf+73f4zPOOKMzlGgymfDa2hpffvnlfpxlgQMAf/azn/VtLrjgAl5fX+dbb73VXzvnnHP4ggsu2HS/H//4xxmAv+eiiy7iBz3oQZ1tXvziF3eO/axnPYt/8id/srPNhz/8YQ4h8MGDBzc91qHsUMCxyB74wAfy61//ev/9lFNO4cc97nGdbc4//3wHxw9/+MN87LHHzj0w73vf+/Lv/u7vMvPuAo67nBx94hOfiH/5l3/Bu9/9bjzucY/Dhz70ITzkIQ/BZZddtuX76unsNuDYXN1rrrlmbrJ6//fa9u/fj+uvvx7PetazOpPLX/GKV2w6uZyXbAZfn++ePXtw7LHHdlzzSy65BA996ENxj3vcA3v37sUb3/jGuenrD3zgAzsDkhdNtq+PQ0S45z3v6dtcddVV+OxnP4tjjjnGP+Pxxx+PjY2N2zWhfX19Hfe973399xNPPBGnnnpqZ3jziSee2DnXv//7v8e5556Lk08+Gccccwwe9ahHAYB/5muuuQYPe9jDOsfpf4dXXXUVLrvsss53ds455yDnjBtuuGHuPG+88cbOtr/yK79ymz7vvn378MIXvhBnnnkmjjvuOOzduxdXX3313Pf1iEc8Yu73q6++2s993759OOGEEzrndMMNN9yu7+Jw2WGZq7K6uorHPvaxeOxjH4uXvvSlePazn41f/MVfxDOe8YxN39Ofzg6gM419GbM5n5deeike/vCHd/7Wn2Rudvrpp4OItk2AbjU9/u1vfzte+MIX4jd+4zfwiEc8Ascccwxe9apXzQ1NPtQE+kNts2/fPjz0oQ/F7//+78+d3z3ucY9tfY5FtuiYW53H/v37cc455+Ccc87B7//+7+Me97gHbrzxRpxzzjlLT5y/4IILcOGFF8797eSTT5577V73ulcnU3L88cdv+1i1vfCFL8QHPvABvPrVr8b97nc/rK2t4Yd+6IeWPveTTjoJH/rQh+b+digubifajhjI9C3f8i23S/dwxhlnzE1W7/9e24knnoh73ete+NznPoenPe1p2zrG8ccfj3POOQeXXHIJLrzwQuzZs6fz91tuuWXbN8AVV1yBRz7ykfiZn/kZf+3OeOo85CEPwR/+4R/iG7/xG3Hsscfe4fvfrn3mM5/BzTffjF/91V/Ffe5zHwDAJz7xic42Z5xxBt773vd2Xut/hw95yEPw6U9/Gve73/22ddymaba97VZ2xRVX4BnPeAae8IQnABAQWEQw9wnyv/3bv8WZZ54JQM79pptuQtM0OPXUU2/3OR1uu0tDlZtvvhmPecxj8Na3vhWf/OQnccMNN+Ad73gHfv3Xfx3nnXfebd7vz/7sz+K9730vLr74Ylx33XX43d/9Xbzvfe9zz2SRvexlL8MrX/lKvO51r8O1116LT33qU3jzm9+Miy++eNP3XHLJJUgp4Tu+4zvwzne+E9dddx2uvvpqvO51r5tzU7ey008/HZ/4xCdw+eWX49prr8VLX/rSLYHuttrTnvY0fMM3fAPOO+88fPjDH8YNN9yAD33oQ7jwwgvxz//8z3f48Tazk08+GePxGK9//evxuc99Du9+97vx8pe/vLPNBRdcgM985jO46KKLcO211+J//a//5eGrfY8XXXQRPvKRj+C5z30urrzySlx33XX43//7f+O5z33uHXKe11xzjU+ft3+z2Qynn3463vWud+HKK6/EVVddhac+9akLvd0rrrgCv/7rv45rr70Wl1xyCd7xjnfg537u5wAA3/M934NHPOIR+IEf+AH8+Z//OT7/+c/jIx/5CF784hfPgehW9tnPfhZXXnklbrrpJhw8eNDPcxnv546wuxQ49u7di4c//OF4zWteg+/+7u/Ggx70ILz0pS/FT/zET+C3fuu3bvN+v/M7vxO/8zu/g4svvhjf+q3five///34+Z//eayurm76nmc/+9l405vehDe/+c0466yz8KhHPQqXXXYZvvmbv3nT95x22mn4h3/4Bzz60Y/GC17wAjzoQQ/CYx/7WHzwgx/EG97whm2f7wUXXIAf/MEfxPnnn4+HP/zhuPnmmzvexx1l6+vr+Ou//mucfPLJ+MEf/EGceeaZeNaznoWNjY271AO5xz3ugcsuuwzveMc78C3f8i341V/9Vbz61a/ubPPN3/zN+KM/+iO8613vwoMf/GC84Q1vwItf/GIAwMrKCgDhc/7qr/4K1157Lb7ru74LZ599Nn7hF34B97rXve6Q8/zhH/5hnH322Z1/X/7yl3HxxRfj7ne/Ox75yEfi3HPPxTnnnIOHPOQhc+9/wQtegE984hM4++yz8YpXvAIXX3wxzjnnHAACfu9973vx3d/93XjmM5+J+9///vjhH/5hfOELX8CJJ5647XN89rOfjbPPPhu/+7u/i2uvvdbP81/+5V/ukGuwXTtiR0D+xE/8BD7zmc/gwx/+8OE+lcFuo/3yL/8yfud3fgdf/OIXD/epDNazHcFx3BH26le/Go997GOxZ88evO9978Nb3vKWQwq6BttZ9tu//dt42MMehhNOOAFXXHEFXvWqV91hYchgd6wdMcDxsY99DL/+67+OW2+9Faeddhpe97rX4dnPfvbhPq3BlrDrrrsOr3jFK/C1r30NJ598Ml7wghfgRS960eE+rcEW2BEbqgw22GB3nu3IsvrBBhtsZ9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbdvOqjw2POnOPI/BBhtsh9gH8jsOuc3gcQw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NLWHO4TGOwuNKLy/8yH7zwG2/U2AMeRbDVQLPM3YACWwba0ATh2sx1q8d+Z+x6A5ai2ATh2o92ZgHFbzmEAkaPOBuDYibYMMNA2+W3Ot237bZ1D73wHIDnibQCOnWbbBY3tAsCdsf2hQMU+wwAgR6wNwLGTrA8a21jsFKj+ZfMNl/EgNt0FLz7OZvvuhzMDoBwxNgDHTrVDgIYDxnY9Cdtus5Clfn0TILBjOoDU+96uF1L//wAgu9YG4NgpRl0gmAOGRQuTAqDb0SFCHPZFGnuHVTDg+v3dbdwUMCiUc9nUC+kcfJseyaLXO/sZgGan2AAcO8E2WygVMCBvvjAdNMIW2wBA3twr6AMPL1qkgQQ8Kg+jEyphgTciG9kfNz3+tridwVPZMTYAx+E0mucnfCFGeeqT/gRVT3ldOHOAQbQleCDGLcGjOgCov10I8t5IevzoHkjnI0VsChDcB7/byrsMqeDDbgNwHC7bUtWpIEJUtovRF4kv6hokevubC13MW4jdMGShZ5HzYgBS8PDwpr9JP2zpAcMcR7Jou0UhzzKeygAkd4kNwHFX2yaZkz6nQeY9hNABAa6zE8DcAi9eSNdzmXPzidSzYFmYmav3BAeBDrDk3AWw+nUAiNR7jx7bgGLT8OYQBO92Qh3fdvBG7gobgOOutO1qNIKCBpECSHkfZXS9hrBgn7TAE/HX6qyKhB5gKnyoAgpIAIVABUT6Xsgiz6f2SPoLdxMCtSZb+9bhTJYBEGDwRu5EG4DjrrIFfIb8b8/TiPq3GGUBxtgFB9Kb39+3SfaFe+GA70O5EyIs7KpABM7qgXAuIAKA+guWlO+o+ZAFIRUHdPmQPtjlzQGh9k62zOAs640AA5DcDhuA466wbYKGL6j6CR6U57BtqPIYAs1nQ5L9X7WQbLtF5Kl5GPVLABhZF3Qu+NIPKaKCiQEIICBSk7bulWzBwdSEK9AFmQoQNtWRyB+7vy8DJAOALG0DcNzZtgRoOK9RhygKGu6J2CquOBA3ZhBa9QJ6+zXvpdlEo6Hvl3QrdcGDIAsxWhhTg0AAUha+IyUgxi6IhACaO9D8tSE7PgCGop+lfvtv2yK0ARRYNtOVLNTDDACyrA3AcRisTw52PIetUqq2+H27AjRg9kVNzLKIgfJ3IiAGsAIHdZ7qdRgBcVZswVtohFABQm+B1VjE2Z0i50Q2SwGHiggGPOzZNGtjdnvSulupXAcA2bYNwHFn2lY6DXut/r3OovTBpfYYFAg4UJcotYWXGcix816OCiAKHAwIAORcsis1MRoISF0Pg6pjcLXAzQtitEK0Gidix08eP+lpcuVRVV5YSgI2/bRzfX3Q80iqayt/zPPA7H9avP2cLQjfBuvaABx3lm0TNDoirk6IEjrboWmAQOIxmAehQMC1y5+SLBDzQOxcFmV0AgFBhFwcUd5jQFJzFGYWytSeT64I2cyCI5znn+6WjjVI6QMnEyijfJ5FfAywuUdyiBCFAm2/zmbwPra0ATjubNus9qRPhNpCtJ/Kb1DlKXAMwKipMimEPG5kodpTMukTO1kmhGUhaghCs7azfw5BQg37u3ogDAApd4EEAEJ/4ZF4FJlBIZTQhszjiWBKmqFZ4EWZsS76kDeNUagmYatwzME3Vn/vb5/D1uAB3HYl61FoA3DcGXYovcYCTqMj3LIsinkaMYBH9rMbgpjoas5MjAV7OgcQZYBj1xMx0CEJMTgEARDzHoywrIGvPncAiAGUclGnVp8TsBAngNPiDIt4CnBPhZwkWZCeBXkWZ9En77/WSQmrTN7I1W0ByOB5LLQBOO4C63gbfU+j5jRsUVoWhQgYNeAYwOORPFGb7tPYFnSH7CSq3P3qNTsmsxKgcnz3SHTZUWJZmKbRqEMHJWTLewBqM7hhoA0LFxgpABEl+XvTlPMACgdCJADTB445IRmDOCtPs0CEVr+uuhLS10RTYl5gF5i2lMIP1rEBOO5o2yT92iEBqye2g0aMToBSCHOeBpoAjtTxOJgImjeVEML4BcxHBQBATCUK8EiinIu9h6NGHFQ8Iybyc1j4FM7V5zJvJefiiaSqTqbpEbpNLN6NLvKOrgPoejJChAgYxMVhjcnmOwK1GAUMKXdT1rbbvidS8x+DeKxjA3DckXYoQrSn1fAneO1pNI28rp6G/BRPg4NkR7jv6rsHUTwNAwFi/bv+JO4BRa3MVBCzTYI6FQYWeRTF42GW/WYWYIB6KYZaOYMSA9Oey6+L3Anemo+oMjzye6/QTjM5YtFJWv/8ixa2eiZzArUQQOZ9+P7ZgaIjNNvM+zjKQ5gBOO4o2wo0+tkDoIQo9jfzNEKY4zQ4Ugc0OOq/GpNSrctQjgJ6v2uGldUrsP35eXs6Fp39exoXkL+NArL+TvoeToTQEuqyf2pFPNbJGBmXYsesMz3M4Eh+zg6s/etVZ3mIS/OhlBZkU1TxmoVwtZobD9dU5Obp5b46tk+kDgDSsQE47gjbigzthyj9RWHZkxDElY8KHk2c8zTcBSAgj4Lc7BqqCEAUTyAkeZ0CAyABDaADQnJ8ALqtkaUcCWkcwAQEDWWIGWkU3OMACJTYkydE1cJPXKVMCU5Z9oHDmxRx12uIoYQ7/WtceSqeAZqrx0FXLm9gYBL5an+cUvFAmAvB699bV4OyqQbkKAOQAThur/VBo/Y2NpGTIxj5GURHYRxHE8WND8pnRAkNnMuAhBMcCLmR18xTsHPJEaBMYM4anuh7RuJ1UA66D3ESwizL6ykjNw3SSkQeEdJKQFoNPdJV9hVaCX0oaghEEqqEaSrbGxBUHo0/1SuSVSwDGQJmzKDWVK89wKmN2QVq5C9ZOMLocBMdZ0TDHAO86n0OHp2vc0H6tv6uj1ICdQCOO9I2AQ352QMNI0ODehsKGBaqmHtvvENJoQp/wVGe5mEG1WrInzmQuPGtLgoNTXJjG5TTDbNKp8EAApAbAY121dHI30cGRAo6rkanIN5HK6rVEnKQ7NT0Fpnl/ExD4t6MkSl1uEdd8FkEHkSiNQGEV4GCQJ2NWfTeXgqbuOZPFhxmKyVqHzyOEs9jAI7bY5vxGofyNGIEQuwCCJmEPLjHYU9mW2xMhDwKyLF4IICAAwX1ArL85EiCEepd5JEuUuU8ACAjCADoEzWtRLTrAbO1gHZdAIKrECTMAEpASCQgYJ85MygDK5EQNzIaADRLYMtitBZS6EmrF0UKWtyIdgSjKCSreSkpzxPBQNcLMnAKRtpyIUO1OdHCfqq1oC1X79f2iL6tRSqblPwvBI/63jhCAWQAjttqtyGDshA0PLNS3HI2IFHvAgFCSpJ4BK7dYC4cBxEIDLIb3bMm8NBGUqz1jUzII0JolfgcEdKYkFaBdl0AhytPIE6AMGORdrDun2Q/YCDOAsBAmEWPDjgzKArHYgQpBzkXbrWqtuJWOGpkwayK0172ZE7TUYUiFNwDoZwLQVt/DwoOUvnL/n6y6171E/FjLpKyH6UhitkAHLfFlsmgGGhYBqUm+apt2BWjJEIvy6IYOWqAoYvVn8QdLYUQlk4egmTdKVlq/AgrmIQg6dnUEBIHzNYlRJF/ChrBwiJGmpB6G1CvRjAlzIDQArODChwpghtyz4bawqMAeh4AArOcarbjBKEg0IByLurVWqvBLArUWjlqGaSo11lV9eZ9dCqKUypgkFN1zaN8hz3tB8UI133UVonIDpm2PQK9jgE4lrGtsidABzTc2zDz2L4CljqzoL8XxSd5mMIBHp6Uha/vYSr1KOjdoMzuLVACEBlZQUmKZwmUyEnPNCbkBsgjgBsBhtwwuJFi29AwwowK1xGF8IwH5amdxkCclYyMl60ECW2C6UkqPkZ0Jaq18FSvrD+aCYjW14WqMKOoZtEF3qCu2qIsFioeJLPuXwDLTtqrdIGO7sPfO/e1b0Gg2vd8hIHHABzbtQVehvwvzb9Wg8Yib2PRvi2rMoqq0AzFw6g8DdleAYT0qQ0LQ8wLCGD7ZrnLa1j4w5qGJaspM2J0VUKV2R5WchbIqxk8YuSWgESIEwIlAaOaJM1jYKpFJ2FGaDaycCI5g9rsZKxlivJKJT2vrk2G7JtHUVK7KXXUtmhiJ6vCVbczAaPQBZEQgDZ1BGaS+i5tFJlJASkBiKrx6InH7Cvo6z5qzcdRovcYgGM7dijQMFvQQ8Ml5Zsw88VVVkK0CchNJfQynoMs1JC3+WsBxQOg4o2kEWn6FfIUbevjoYBQDShBvI20AuQVhmdwxhm0ksEKHJkjwpSK5suAYyReT9uScLwtIWSWjEsWkpRYMytRiF6XzAMuKjOPgUMAIavOpIALR5KwjEjAoJ8RqfUgdVal2o763eFR8TnW6QwRQCql/pVArZO6pR54VK8dqTYAxzJ2iBL5jqdRNxt2zUavjV+dTTHTzIBnOhUUUmO8R/d1jsJjxCyLLsykt0Yam94DgJKXIAk5iIWXADPymJBGhHaNMDuGMDsGmB2TkY/VfC4xKDJCZKQ2ylPeOA5xLiSUIYDXAFoRJOAJodkgIKgqNBPyagMQkFYbcENo14PrQigxmoNJNFsTRbmohXk0kktjRKg39IGkYWcR1GZg1qJO83bSsTEAPOqmiwHxRJjBs1m34VCo+p+GDFLhR8f7WKQ4rQVjRzB4DMBxKOuFF9sCjR5PMQca/UFK/RBmQbxsoGEhiqUkJZsCD0kkTapPZqoaganHAgKQGMF5AvUyxuJppBUGrzDiavIYhAAQMRIiKFOl34B7PQYkxOJ5UGbhRfSYrt8IQB4HCYuUC+Eg5CpvkCg7rfamCUDlZdlnYs0wgZSjsdNpq3Cmr+GwOhmriQEcpF0LsqjmJZBgQcWn2HXvcB8BWrJ/dPAdA3Bs1ygszJzMAYb10axSry7y8n/kpB2bbkP/xsZvuIdByFGJy5GSpJCFRiw3LLPKEKIsWg6k3INkTXIE0koBk6i8hACL7D835FkSDgwQI8aMpklIKSCnIOFBK4uVsvAQ5snY4tfCVeRImK0HpDEjj0eiz9DQy8VoVL0/EtJaQB4HCRUsvLHrCsCK9UKbJZwbEfKoAdYahI1Uammr7SmxeBX+/QC1lFQ0MLlkYICi8zACtX5IGHPLwYnTTif3HDbv91Gf3y4HjwE4lrWtQMM2qcnQOT0HdUMUBxJ5b0mZVsVopKAQS6jCWW4+1oyFPdVz/Y1qKpZCVRBnnodpQKp/8w26BDxSCkIeanhU/6NF97+GMHkMDVMgoUpTjk/MCG15C5N6KgFIbQBFIEx1wVvokakj/rLrlBt9/WC3T4hwpgmUyzX3/dnCZQFvioa8ov3gXMne6yl3eg+QNT2qupD1OQ//f/nCFlyo3WsDcGxlzuSHBX+qwSBUr1X8RV3x2gtJPH0YxdvgGL1RDzdCHHpoEuXpHpnVK6ACAJCfOcpCt+wD+cKWp3S0fQUgJFbSVPEjA5QYcUpoDhAQIloaIzUZ02YMTqQkBiGvZFAbRbthfIcCRVqVhZNW5fU4EXFZWoEL00h1G5QJYcZyLglOmjIBtBKkfEUJ3k6LAADYU922Sr4yEdLayEMY17K0AWQ9TKyzGbN6NL0mRQ3gXcJMCGaFdCmjMyJCMy+McjwCUPf6cI3HEWgDcNxBtrCLVw0uPW9D31Tc59j1Mkyk1Slmg3IUxIUA9BNQMCp68go8LDa3uEDfU93TxAC1KuaaATQlIEWwFrS5/qLGUC4hT6mfQeWGG+gJgNjCLepWO7bxNfKaeBCyPVfnydXnpKyAAwE9C3f8eqpHhia410BBwxBmECfUM6s29UiMQ+GZp15rtSqRErh1LxEiMHqAsaimZReHKwNwbNPqGpTNK11pa05D3iwLfCQNe6zfhmQaAtJqFNCIVBaiPkX9aQ0gTLK79zUJSlm9kAjlA0qoY2a1Ky4ZZ/VoJiwp1EQIs4g84hL6EFzwRaxePdjDEBdtoZxzHomLn6d6LpYJ0r+3q6Sgwg5y9rp8FvkXp3LctKJiuEa8ldFBySKFaRYhmRfNwetnclNSvsQMaoW/COplyQUpXIqNkSBr1GzeBI3l91YHXpkCNVCnD6oDgnslgpKb1rTsUhuAYzPbTKw1t5m5uuWJtSWnQdXvkZydhzXnqUHDQ5Ie/2DhBeC8QVFj2k/SRbr4qcbVe2yfIckTOUxJspFZ43vbd6OKUwtP9Lzcs7EnrZ1DBLLNaKk4HC1jLefKJWQyj8MWe0gql1fvK0eouI2QZ3rcVr2oYIsWxblS740YYCYEZNG0mOcUehdXvw/WEyNvsCzHRNIpdza028BACWn3tRxIjhywqG0AjmWtIxcP8+FJEyvtBpU2eXUxG+lYAyM/KzI0j22BUAcM0qgsJnviA6rXsMUL+GJrDmaEBMSJVJimleJh1KDBJNtjalkbaJ8OTZGaSjQL2Zmjkp4NIyiHEaa6rYLebC+QxyJVZ6CAzRgOeh5KMLol/wQXsXEEstXGQDyEmIGs81fSCAAIYVYDBnlPItKMsnkgYEjvUw+NqChIY5C0rIG9pV1NBm8eiDU/JgIQwZjJRaz0Hp3+HgHoeh41cbp7w5UBOA5liwb89EYXlp4bFajYzx5osLXRMyK0Ijo9S+AeRzmkLSZ/qukfFzUlBsR7CDN1zQNADcl9GkoGpvY4ZGHVT3r9NWma1XiJUeEyLJQIbQUcBgwlaVG8E9V7QJ0YW9Sll0jZzupzgnomlMs5BZeabvXFyffBmUvNDJf/L9vo99Sf5XIoj9PIU/M8YP9fi8h6CtMjyAbgWGSbib4stQoUMFik1bB91KSojRSwbuWq15AWgNI8hyOhXSml7RyAuAGvByFbzNVCiNMSKpiFBMQNaRjcHEiaoSnhD0G2z6GIteqaE8oA2sJJ2NPa+ZIAEJP35zARmfTvMI+lK4RyxWs2j6PsO+jkyLRCWlinn6NlB63QMpqD1f4aII2D8CN2/iZvN81IVG8Oov2gqXRdt+3q70m6x0eVsFcPBa+knRU9SPU+ikF6dliX+frvNWD0U7S7PHwZgKNvNWhsMt5gqzRt7W1w3wMJFuOTpx79SUz6JI/laSu9NLgDDH52BDC0FsQWI8xLYE+xujrS3lxzJv6z6hdqQKHZF9InNmWAtSdwSBJpmMdgx7VjUJIHOffdIQeisl8jZol0+Fy91nLl1Sh4eJiRCTlyCUG41MTUWRb7fByofLVe6KbfRZ0lgRAincFUOMQir0KbRbYwy7LLbQCO2ha4pwuzKfb/nbdWv/dIUABVuTw6tSmdruWxhCnEDDZ5N+uiQSEOXeathKJpMyRzAG3jBy8mS6umEIWHKn2ClJJwG9CQxp72vtBbedK3iUDmYYSyTWcfKF6Ihz/Km8QNITzNU2gmtuqCqFw1MxRaCbeajYwwZTT7W1j/0jzWytYMrbpFKZJjAT7JOgWkFeGNwjig2UgIkwQe6SFNem/NoP2LkdfDNIlEP2VQTD7uss7EuFdis3GJir7DUrWVqvRI0HYMwLGZ9b2JzapbO9v0hF51VsVi6U1sLsTWqtZSOVp+sm5PMBAy0gBOMFqGIcdQJOUGWuZpdA6ILojU3gFXXkflBdRZFeM1as7CEhYWphhYhApoaiUpJUYAwUSbBiwWjnSvQ+VpeINk22f9QeBEK+dKlavfiwEN19+TXxATjWaZb2PH1ebKWxKbHSl6UZgeKTYAh9mCEMW9Dec4yuqWEYlZiALKEAaSSs/QUSOzUQIKv2HucOZa8Vw8EBbNQkgliyL1H9zJLCBoBsT2x6RcBVwY1TTk3kdaIczWyUlPUh1DDSS5EW+EGxQOArrgdBGV5kHdf3GDESqupV3TFoATVE2GDAAs5JCMkF2DkAhxwuDMXpgakmZ8snw/7Xr0a8CadRLhml1MhqW5rWERGIizopTNkUCjgHY1Io+1i3vFj/j3azVBMSBnRowEmjUIB6ZAm2R4t6VqAfcopCFQ9qHfC2+1QCW7UnMpu8gG4AC29ATKJtvwOFyfERRAAG88bJ5Ih28wAq/sIqigMVgYsCgT0Dlm8UDKCyJNRyZARVue0UhGkKqLbs6RHYN7+674kDqVa55P59x675XQoWxU+BA9vnskhAwBjPp8+p4Nh9ApRhOA446X4Nkp44hi5ZVBQ8JEThYDei5s8ZSBpHpmqbr+dfhZkd4OjgFVUVw+Ij0NswE4+raoW7n/TW/YWM1C6WkBvNq1CeBxAx9+RN39WKYjj0OV2WDPVHj2Qu87y1jYDW2ZCN9lTY5S+X8f+KR/t34cWeXgaSzHiCo1jxMW70M1Ha4y7XUUszSsLfy0Ag8ZsqZsRcVa0CQ31a9MTq7mBkAjWhP3ilrRoljPkTwizNZENzLanyXjMhUVXFqJfm1Ms8ENoV3VBswjQpyJytQ8w3pYt/Aykm3Jlaam9mjCRguaJfcyuJGLQ/p9EsQLRduKvN0EYLWZV7Iou7LLPI8BOLZh/VaAc6KvfiFbpSItbf+KW+6qUX3q5QgELk9h2RCdJ7iNKqj/5lkNrkIC26Sumq04DUJ3vwB8sXX2qRvXnIi1J/RzMi/ECFCqDzJ/nNrT8GwKF28px+r8+p/L9lt5PtLwiAqg2jqsvSjdh4vLogjIagl+37g6fwN0tNmb/nSsKv3vwuQCq0jRTft27BJR2AActW0y5sD/bJ5G08Cb89hkeZvCZoOVDESyTl+3JsEjrX5tSHUbocjGGd3FV51GbmSBxFlZ4MaJmFufI6tClJBGLBWoLXualxjSAdyAgsgFXmFWkYj1CtAQx3ptoAIPdvm38hSz4vk435J7oQ7kmoQWGO/LCIlhzZNn63L9TWYu+yU/3zDTeS56eaEOxJyYTfmFyBlxAperc1TuaFSBSgsQWMdHVJ6IhihhkmRC3WQqvIZ9PzkLELRVb4DNzLZdZJvNZNnh4DEAx1ZWk6K1dqMGDQOTrTImpKlP02vUT2rbJohr30mR1k//yhnphz1c/dGVqEFcBM5dSboXoEE7ayn/Uf5VXguV49n5W3Nj69xVZ1XqalyghDT+dNfPZtuHpL1QG3Htg5bHk2UsqHhCaAkhmj6lAFS9X6DymHTh23kHANk8Miog6GX2qDwzKsBnmRu71qVqViXoLOMUPDTRtOx21KJbDnTa4XZ0A8dmmZT6d1cIVjUNNWhopy/PjFRknbe5CyR6iljGBrC66jJlnvxp7268LsSQ5OZtuPYIyuJOujp8QceyqGsgMg1GWi2hhy+2EboNgHqAYeFUCYO652m8jINcld0hqwOjcgzhVBhhKp+NdViU6D+4VMvKr2gOJjBJTQol+ztL5oJ6/JH1H1GVqMykkc5i3mbQvCYCwkT4EvMATaQX2gyy4wAlHWvZFKuSVU6jZMYq72KzsZKdhtd5V4LH0Q0cZnMkaE/w5aXxPa+iUoHWnEYtdy6zUXTBeoYFZfExSsVp7WE4D1DSidKEmDtzVrR4xb2YDmnK1fiEBFdVwj0TPVztDdkpVJxKJSnxcyGTg8/gfIptX/aBAoT6lLfmxDUfY+dRsildKblXpy76+lLvvINc59I8SGp2QqVW9W1cHarfCwME1ZSk7BL2hf1IM3dDkPr3GjR0vORm4coh+5TuQBuAo7Jat+EdynujG+ff1A1TOEbwykh6YlpdSiAtSVdQqa663bh1WFCbPDmBuNGCmDFblw7h073B2wl6ejQQ0ljeZz1J4xRgYudRQluAxrIq7qlUylIAklFM8Pkr8gHL35v9jGbCDghpRcve1TuxcvZgvIqqW62Pho2zbFeogGgqn9kyHYCGe3otiTOYy7zcuGEIIUrRvBLAUd4nw7AZcdp6nQoSg0faC4Ug0nMrv1egiAdbhGlCODjrchRKfvtQJ/cwyr3BVfjTycRRlk5iQPUQ0o5jIXcrZ3e4Hb3AsR1dBixUCYv/WHsgBiAdb0P/pE99+aV6vz7dGOSSceMDrCmxhCXqMisvkCFPbeZ52XjQBsLS2o/9mDXpZ69lIm/40/kHFGWqeSXmDVVcgsy0Jb88OaLL4wQ5BsXyNBUSF12Owo7TEDgyKAcBEOU4woy75wDzwrgSqlXVxQ1JzVlD8hXN5Op7+BMlRW4ZLqgexBoS1doUjjZtrgICkgeLDd1GFabU4yMX2nYUyLvAjk7gqIlOe6nvbSwKUVgC9jIvJZYwJeoTbNwgj2IHNJAACto0GBZDsy9EAiMeTAIKWi1LVr4e5XxzE+RJOEk+ckAGIIWq5J7RHID24WDXYORG+n6GVj2QoFmaRryEMBP1J2tpfU1meuGdAQzEK0CW96YRnGCty+kBOaZUu8r1s/L7dkM8gjhRr4CBHAizPQCHgMmxAozjW+U6NRvVtbIQpmWEmfa4IOl7klaDKmBJtSUBzcGMyACpjj2vNOr9SXYrTLPzJkipSv0KNwI04MgIk1lRiur3TwA4R+0Gpp5HkolxRph6Gn8BmJioUEYrhK7XscMzK0cXcGziZcxNZPPN+5yGaTgUKGpuw/gOAkqRVeE1ypAglNoKoOgnvJCMQcTaQIYcFHJj1Z3kgiiv/tT9AuJZZLLjFym5F5xx4TbsdTAQGrg2Akzde7biBUBV2Xuq+AWqgEM9Dj+mrR3dV1ZZuxGqJjSrSV/na6KI0aCnHgKQk3QZd1PPp9MdXhW33vA5FL1HrkPIUFUG63HtOoLtIWIXV72JOgwJKgJMGZ1eHJvYthTIu8COHuBYkEGR/628j0Xp1/r9lk0Zj6QOZVQuH9tsFAgAuG7DlKGaHbE438hSq2QNM8kCxJaLDLsp2+Wx7Fv6blIhQe2UtS9GGsl700hDE5ZzaVdlkbbrcKBKK5C+Hyq9tuY/XKIsWej2v9oro93DSCumq9DPkCt16riSuRM8uxIm8lnaVXKgIGZvCWizamtMyBHI6yYlVx2LRg6hLYjEWsiXR8rzmDI1hdJFPTPSinIgLlunTvm/8yhZYjFpBKTAkLNMi0up8F8r4p7xxobsQHUd2wWILdO2O9jrOHqAYyursyjyP12FaG2LQCWzcGMBmlUpA6NLnUhpmAPTBwDlNaBIpuvMSl3cBsBcjI4EHUBARbACLtySzAIj6qLtdNtCWdR2PKBwMsZTmNCrIxCjsg80ugBs3xGwTmPyGQ3E5BgyOMqOSZ191b1HzEvLFdkKEIIW9BUAsZCHnYh1UlKJZw4EHknjpDQOsG7rdj2MuLYpcyJoE+8iAGXQdW/mrC9uG2DdNIfmOQ5luyA1e3QAx6G8DQD1dDVXiNahiXEb9T/An0TURHCQgdF5HDyMKGGK+PCmD7DV4VmDqClTq/TUQUpWZRk35EbKY5J2naH07tBP48BQhy+lalUyK2mV3HMgBuIERbxVGwtYZNV4cGM/uehNggJMZPWKuGQzmDQbQ+CZbE6teEZ5JNwLreo52mLXf6ZdsYxPHpeQLIzEEwhJPB5J7eoVaIGQM5rErs61wuW0IqDRrofC64Bh6fS0GpHHUkWcG8JoRAgz+f55mkGzBIok33Wb5rqB0WgEqYIOKGMsGdy2cyDS8TK8JUBfPbqzwePoAA6z7WRHzNPov6//2iZ5eS+yIshMD6DE/Q2QM3VxrBJOeYoRkFRuKNxHmGX1ItQ1rjya2nuJM5Iw3FSWFX8CELhl7alhMb8eW72LznhGFG9EvA4uYxjsaR0Z3LB4Jo26S2QeCHlJvHwmKdhllXz7rJVK49G5xKF8Pq+TMY+FDJjh1ykkyTSFyhMzL8W+k1p5KileRkYRkUn3MvYQoTRaCnKuowYcQpl2b5xHhhCmLOcwJ0Wv+nN0VKZ+I+xsoOjb0QUcah1Po68QtfSrcx/UBQ3N0UvNREWSAfI0SgSaARSi9MswIImqcaAyxrAje7Z7JtgNLb+O9iVh/SetcCxpJKFBgGsmvNlOLjNISrWl/CsiLUvhsoceeSTVrc756eLyUIeA3LB4CmMGzUTFmVYENHgli7SVWA5r4DcL4JaU/5GB1qBCyI72kXgJLTrXQ35REOMqTJPTdo/J8sWUCHEGqaYFSm8SFZnlhlTXIqndUvwnnAg8bBIOhdUzIm1PkCggjKPI1sNYACRJ/wPamKhArYANeXamF7LUYLPLBF99O/KBYyuSqs9tLIpfLUQBnBDr9Nzwp2mANeypu2e5u0GSnjMp9pwI0hWcylloutYESnmtqQg9LW6LJI1y1ZiUHDUlZrVI05g0+2CfDd5Don7N/2a6Cao+iwGKHosbBo9Yak2a7Is+NBkEoG2719PbFkb5bJYpap2rkONknTrvoJio8spQ9VRVT6Ptgkvdf6PUo8BByMnpyH6t6t6prEpOAlw7I7oVvTBe0qtp09pVMn6MQjcb4xdh6zoWV5HucO/jyAaOBaAxl3o1bqM26+zVVAVspuuIQapge/NevWEP4B5JaforT/oArd+oOlgBlYehi5lY6jjKhHdCuxZRwgdGcxDgYNkbS2lqRsGI06jduKqUaC3ykp1Vr9v/RsXUiqilRCo+IyVMBTRoNSGMMogYOUmGomkSQmC0G5LjtTAjj7lkTjKQV2RBz5RvCRPIFLmpXZcCDC7Bz5Bszkw7vCdGnAF1itT6kDBplW0tYVfgyCMCZ1LOp6RvrcVi0IZHIUnGy74nRGhYQiDo9w4I71HddxTLUKfa6+iARmck5CZh9A7NrByZwLHIy6AwV8DWn4NSsioCEGQeRdOUloBRAaU+Rpb/EJNnVShx54bLmbw2wio//alfR076dPQbfKUImoDqyVp/RFvgvXoKykJ+gvqZifJ+tv/vUzj2OpcXrHt5Bvx/eBa01ox9HzlJuz1hXzV1q9PT5ipu5UOr7oOcR5GWAHAvxzuea7dzqloqeldz8t0JeDN8RKSbe2PmvVVd4hmgaoyDNQsKMyVHGUUVbFXHMXQXdi03B0qzJ6+qNZdN7w0jwXe4h9G3IxM4tmOhAotQAYlnUoIDBo8a+fL1Z3/gs6lDAdYhxwy0ufAEzMijKJJqU31C3eWmWsxc3cDKWyTVgdg20ft4ogs4uVqI9loCRpOKy4hVhqLSTHhlrn+e8v+eJs0AzQjcArwqBCDNZNFwkqc7rWRQzEgaolBgYJTBq9K5nGbkB2VUIYK+zCvlwGEG0H5pjuOzVbR3qPX9kOpieE8PUbdyJ1QMM+mOnsd6/auCOgdDTc0KpxGQQV7jEiZJun+p18ArTaX3gRClDUTfYaDhTYrJHz6dFK1l0no/N7Ud6HUc+cCxaDZKHzRy7oYrRogq823kJmAewqG/SI+rgXKj0OJit44EXY0b8sVVKkwZcSpcAq8UVam8ASo1R/EsGF6vwoFAsYCOfx4DFd0XB8l8lM+hP0sdmZx3ANDCxVMcIUQoh4730TFd2PKGMiKSxwy2vqSZEDaoAxC1nqScmJ43IGlSPdfQaotA41tm2TNdSPA0d6cNAorGxsHJBj2lDMricYBZ2ylUnmoU8hfjkXy2sbwHMwEbblsACZhV3cMCaRnCgqrYXeJ5HHnAsaAORX61p0RvGhvQBYFa9JUzOiFJLRDrvcaL/mZl3L6t1o6MbFxBJQoDXPrMRGV+inIYoZV4PUxkIeSRAJgBR5ixLxzrqOVjCwCJ9wOEhwhAjiVcSmNVqcYiEzcCk7JwDqEKF2pdCicgabQl3boI3OSS1GG4K2QaDxl0RCWNu5ZAQT2XWRC156wAB4ICTDS+SHaZo6RefUZLAsKEMTrQumdHOsTJQjyyqED5IRfmWVUsgnhPzoewaGlmUl0btIaFx+p9NpKmxaoBsYx9pAMT6d0xjajnsGw6jNr+v1dVu1PtyAKOBaDRl5R3QpPq/71wrU6/Vq4nAeCcQUqG+QzYSgzWadwDAFFveFIB0jjIz6bcFB6vW8eqAKmY7SlP01j0GXEcimoSsPWrre8KUBQNh+oXLMOQSkfujmTdOIgWMh/WOJigXcTs3BhFDKZ/9/MAOnEOZ43JtPy9eCFSE4wIIDJGazNQYKSkAroNSelIA+QSUoGBOJWFLgV77EObDHT7/VJ5RCBL6xp/BEYmQSN/ZtTXJMD1G2lthBAIcarl9dMZqO2R4fp+H/GZIYJAZiFJrddh30ulLQY07bDQpG9HDnBslUHpg4YRYyoTLtyGyob1qcBJAMOBpk3AqMS3dvP0J7OhCmsspjZlYqtkZ5xps5hpj7xT4Vdp7Q/XgFAG0mqY1zU4cBTJtakvfZugPUiBuY5elgrlAFCsHn62kBrWJ7Pi6EjDDA1JiKuHZ/01JCqAQSjpSf+sksbdsz5BCBnTtsE0NpiuSnf4MNPFrSllMJA3CHFCGrYJ8MZJdqBA32vT7z9MM2im3gcL/2JqXZfhV6Bh76UUESMh/jsBSeqJEAg8HoFQ5uVwlp95FERcN5LqWTTNYhAIBBulsNt6cQBHAnAskJNvmj0x0AhVaTwgGZNqu4V5diJpSDyKQrTFal6KvEmfxjbguSLiSKXiGn7IE5N9QJGlAT306C1oq7YF0FFCuiaESdWOcNCIG+UpnBvSzmFFs1GnOEXcpbyCaUyIHCBgC0ojFAtl8ki8Bm5E1UrjpO0DIDselxQlAWhGCSFkddIY46ZFDIw94ykCMTbaBrNxxNeJMZs0mPGKeBRTqjwa8XaCgWrQsM0uWSjX3Wp/7H0OFLade3SGflZdi0oHI/cGr43lO57O5GfO4Fb5FcuUZUIg5UJmKkvXLAqNGpGgp6SCv1z4qV04emV3A0cvNFmkCC2bUgGNGGApVwClQKkvBWYNsPVYHKP2r4wOEOYCUwbYOnaPgldqmqVRUYNaS8AwZVCrwqlKLSrHhqcaA1c3cix6EED1Bln1FSixftxIZdFoiOS1M1TEVlK1S91Sd3l4+vkYJ2KNbrzYbcxAk0HjjBBZQCFIWwDJYicvfycAx6xOMIoJe0ZTjEOL1SiS0QxCmwOmowZtDlgfzXDrZIyvtQFpIyJMYvEMFDiEI9IWilzCsiJs01APJVyTyfXGtxhQK0mt3lEpw4eCp9xLaW2EyCx6jZzF+wCKu1LzYcwy7c3GKWTWMLiOjSDg43zHrH9372jb3cBR2ZyXAXSzJ0DX06ik5V53EEIVhhvQUNFv1H8DylMQcrNS9RTsNB5mKc2Wmxiwik6q3HsDGut1YWMQPFY3RWnKzvoDQLLyfAtLTH5u2FcLzQK88U5u4E9zNmLUitqihAfZsieApi9Yi01Q/bPrzggxI8bibhto5Cz9MxhAIMbxK/uxt5ni+NF+jChhkhtMcoMvbdwNG6lBZgGS0WqLWSIQR1BLiJqWtS5j3sPEwrUR6bXtho9+L1jXMIY/5SlDOqgricrZAJw0vKsk6o2K/3IFEKqd4RhLejZrSGO1KVGzLjnLBU4JmM7E+0hJ+J6hVuUusk1EXgBKaIIFoFFXu5rAqz8s2nLvlaR8Tl06d2zlNOqGMgGu5QAXnqCrLC03vfWSkHqWMnOk0zZPCU6rbfHGO0CJ3+2Yuu9OExvt15HHAKvyMlvZfFOBxsh6aihYBBTiFeVcavCMMaOJWT9uFT6w/J6ZBDjGB3D35gBOWfkqRpSwkUe4Na/i6+0aACBzQBoFjFdatLMI01vEie6vTlGrp2H9OEKCt13sm1bwd2qDTDHuk9xGoUxxBHm3M78/mijeiZyo3hvQPofmqlG3HiVGAQ6Il4E2OX/GKXl6djfZ7gWOyvrl8XPpVpeMU9cj6YOGKkIdMLRRj7u1TUAeNy4kKtkRjaVtyJHJl+1GsjCiQ1YK4Rk15Tf+euvt7jjCtQg5ygR3QPYZVYruxXD62W1conTnrqppKchDbixZinZdXXjVeaQE93SsaC6P2Jsel4Y4cO9Cwiy5lpwZWBHuYmXUYm08k0lpTDgwHSGlgNlMYp6N6QiBGCNKOCZu4NTRV7EeJsgccHPeg88eOBG3YgVfObgHByZjbBwcgw9GhLZewCigGCXMMd7FRkTkcWkqRM4lsXt/qCNQ/d5s8JJFi7PjVrQBE0Ct6jiSfL+IoUx1s9qlkd47gkzgUQOi5A8qFxEyg0Ir1bMtyc9dOF/2iAAOt7AYMDpS8lodaqY3gwOGAcgoan2CfPnWudwFXC4EQmfweL8WpBZplXJtePaFMiNsCGkW1hp5YqqXQBoiBHu66syRrJyJpSq9d2YqwiXkUqafmwIeADwTwk0JVTrZnJHyKBqaGL8BghR+AcCMvCdRjIyVUYv1kQBHygEHpyPxNLK4CJNZgxAyAjHWwwQnxn04LmREIqynGVaCvPfWjRVsbIyQNiJoForkvOfh5EgIzOX6AlWGSa+rVgWTgkdxhIrXQIB0NN+YKefE0puUYhGCZfaqV/G4unxFZ0ZwK4JCbgBK+nrdLQ6Qhj/2oFFPmHcRfhxZwAEUEhQo6VZrzBPi5gKwlP29bH9jlspUzaJYgx4XZ1VhBNkYgSRNeCkHGYKkXAdN4LJlf28Ub4YTKXehqzAQ0jh4RoOy3+ZIq8ryGzZqnC+fh5C0BwitFIUoN1ouHoEwEy8oWycvI0RbwdMcuJSnkPAUVkNiFbL2mdNqBo8YsRFiFACyeSXEWBvP0MSEGGWcgYAGsL9dwb8368ggRCLspRGOC1PcfXQAt8zWy8GnQWTuFmIYoZtN6FauQxqTtCRUrihMJV072p8xBuTYbfYMiKXArXFxXmkkhZqyC7aajQTSEIZmSUNEJUY3pvL/owbcRIRpA47ZvQob3MXq6XJT0I2yhcjUAR/hOXYHeuxO4OjxG14oVFvoeRekdQML3l/LoMFcVJC6Hx6JMCmthA5g1AOZg9bAS5o1+1PaCtTCLEv4odun1ej/b+QmtbmkUMcSyti4Axu+LKXphZyzDli1nkNQRrax2SukjYVDq6SnTVXLwmGEpOuF/K3wQryoIrJWn6ABorwcMTDKnmIFCnAEYoxjQhMyRjEj5SD1KsQ4mEY4kMdIeqAVarBOM6yHKdbizPdDrfxzkZoCc5jBwxMroRexloZja0CcEJoDAKWgXdJJvKZsPJB4aBlRwHEsWaeQgnMemGWZG9tm8USUn6CUwdMpkBLIPJCZNn2tFcRkX6wBCASoe+0ntzMucqfZ7gSOzSzrQOLqd4QshRihfEEd2LCYtfrdupdzCCVpoNoLAFJXQeQCqHqauvSrjAVUtL0fsWRE5P0knbhYVY9tcXtplqVye0SgKp0r2QTNzhCUYIXXVhTyswqf9Pi5kQbBlnK1YU1WXm7hhzzNyXkAbhjsXAdkISd5PY8YGGeEFUGtlAL2bazgAI0RQ1adRkIkxt1WNhBDRhMyGs0j/3u7his3vgknNPtwWvM13Mpj3JpWcTCNkHMQL2yqLf4mELCwGrHGQjhoeT0jNwKgaUyY3k2EcLO98l3GWUAT1Bu0gUxEWiLPCNNUQiC7fK14GuHAVArYFAg8W2IycvvuZ62AnPEVNTgEQjgwKcT8rHVug1MqJKrdj0DXE9mBtvuBY1EfAxfYqDzbwCMzbApXp39ov2bF07AoXIhlMwBXYjqTbu3yTEVqYEKWASA5tpJrBNFvMIWSXTHgaDWFp3qKmsikBOlWxaUUvEjVzZ8vXoMRsJLqRdE81FmXiJKdUDBBts8IEXcxqYsfSgo5AtRkxEbnlWTCdCq3U4wCHIGA0LRYa2ZYbWbYE0XolZmwv13BjdNvwL+nPVilGTZYvJBJbqQFQSaEVjt3aRrWa3nUyzCy2ep4DEzyekZuCWHMaA8EpDEhTpWXaskdMu/GlowTghatkXskmM5AsxY8tjZhdo9VqVMiKUvIDEym8lBZHZf7K7FPuudGwiHWkMeHVPdl5zscQHY3cPSFX/1wxcw9D2mUSU1TPI06i1JlV3gUkVdHkp4bBy+CMhGWa0SMOFOuITfSKZtHIvqyGyCtxbnaBgtPwjSBJpLTJ309biSEmoBV0BOPg7wAK04q3oRkwJCdW46EtBqQsoxVoGBjFzX7MALaNStDt0etZWwgCylJaz5U4w9MB8HTCO+sycLVgAEaZVCU0vtJI9LrlabFdHwQgRj7ZitgJvzbdA2rscXX2j0AgC9tHIuvbuzBxv4xeH+D5kBVYJfU6wCKt5WKJxJmjOYAIe4FqKc0ZYKX1xclqWVASD05yOJvNU3aSIiK1RVJpZLWohjJOVIpuWZXavBHSqCDmjs2rswUpE0j3sZkAp614nF0it12JlD0bXcDR22bdFBy78IbyxTuopOKNSAJOvN1FAUAAqlaUzIXXGU8AAgrn6EcRgLWGuUKyFWagDL9LhxCecpn8Y5I53XQKEo17EwIRfbSU0D710mlq5d9V96Ku8Z6SWIooVIS17wMeALyGEhrGv+bF9N2eQ7KChqVlyIxEIBE4DbAhWCtgAwzgSOjVVL0YExITBgF4Tz2TVeQmHCwHWGlabESWgRifH26hn3TFfAkIkyCgIZJ49XDKr1KzNPQz54lZAkz40XMpYL/PbS5eIIE8S50n0bAShgCYKRAP1LBl15bX9ZRZ+WkDXjD4jrLMp2V78CAg2QsAyedIWugsUvAorbdBxw9YtNHN/qfuy5eEX1VZGndO7RmtmvQGJW0q6VBwywhI3pGJI0Dwkx7ZFivh1lGA2i9CHkHLycx63JtBw5U9TKhxNJs517OsZnIk4t1VGQeK5mXshd22XwQH/VIQHOQBTyIZTh0A31Sk4OYGQeInBzw0MaGL9XpUGpJirMMryaSOuU2ggNjloF2LE/TaZPQJiEiZ61ku1IjgPLP+4/DNEd85da92NgYgQ5G0YkABTRRFjcrVpnQK8xIr03G6tdkAwPMeNC8K0JeiZKWTZL9KBUFmnpvAqxJSjBCNACM4GHSnFnIYRm5Ncl3k42LbCXN3glFgrUWHOn3nNXz2D0AsvuAYzOr06x9M2CpGe9Kxu2T17Qpi4wmoFLExlIwRomBhn1B2mwSbskJUsoMtIzAWUAt6CxYdWWp5ymUVoDi8fh+EouX1FRsLyuRR4QUhfAtIjTZLo+CCskqrwglfRnaImsXQOxfK/mDVdN2+I/+fa1kqns4mnUh7deZRhKuzJosvAVLVsV+hpwBROzDGNO2wcEDY+SNKNJy5Svc+zHeRv+31K0ouGdpT9BsMFZuYZ8H4/sJknYNKaF/l0g5PFwhC0CUnbUyNKFLhvo14OJtEHndE2uIQprql/3UoaqOsYxBM7C7Iw1rtruAg7oXvmOWUVGiqiMR12HRgujqGqr4BiGAV7R4bW0EjgFpJVaiLauFIKTVxsMXn7fR2v6BPLZ+HnC9hzS3gZOrIWWQ9iJ1F1kbHlObETamzmeACHnPigCYNQXSGzSPpKXgbG+s0pLotgDU2N/7eTTUoTLQAtF9dGi9irr7/x7LYg2SRaFQKTITikhNhz6FqZCZtqhDknNLGwGpYUxXE0KTMVppXduRMpByg1mKyNMIaOjDJKGUFfOZ+tWyQlYPlCYAICnX0TQhtEAzYbQgJ37Bwje1eyJiQ8Ak+dBpoHAgRDIikgOhIRIl6YGZtIHUqlheGTu4ABCuox6BYFyGhqCY6UCmuvJaQxT2sGV3eRvAbgOO22DMDDJpJ6pVZSGATZlvQlGGekqzhAji7oaik+g9eKQ1n92IpTakLpEHoNkJdF1fc3OJQKYTUG/FSuodNPw9cPDKOhvFn84M78fRKSMP6JwPAeVBZ093qOcAwKbQ2+Ail3wDngIuxWamFamyFgnOy+SGkQnIiZC1Q1jKwbMsSfUTdq0pFLm9q1rVgzDFrAFDGisXop/dGj27XJ5LuEKthgnWf9SuR50Z839Kvtv0NmbpoVohB8dQlKRA8VKM90jJeba5IUw5YzcVttV2ZAJH5W34gCX5RVzJUSOexngENAFZG8e4BDzJE1+qFkkGK42qiks2/QSrroGQoqg9a/GUZT+i6j/yKOiCJo21Vd1Jcm4UIBkdy+yEIE2Oo7jS8lRPfo5xmoFb5WZv1xR8Knl70EZB1IgnASKvzzLRGFX3bR4BuSVvaOOvawGchSZ5RcvZiSHNecQTiBPRXdhCD0kuRNwQ4Go3JB05mwbMGsZkJYEiYzRuQQSM906RU0A7bpAnASsbUuBmoyfbdVuc5XuIGwqeI8iBKwAcHWDnZYhFLRsaIZxr0PAQzK4HSbEbExAPSAjMjfVE0HtEPRAApXKaNe3qF048CgBAoxVHnICUwVoduxu9DWA3A4eGH5zZW9r3zYlRwIlRl5UrR1C6dBUXghiiuYgKHoGceHQhGNtTl5ypX3gOlqbV8nauuRj1hqTepMt1WMhTfRgUMTicG4nTLB3FtHOYV44C7tkwd4lNAwwvXiuHkOLO0H0QBkCqXdXth0V+gHoc5NL10ApVIMBVjmlP85wZYRKkdwlDxyFkhJgxHrfChUDCF/cQ1bvIOglO3givn0ljmSyXq7tZCv24CN2sz0bkUj1L1fnZ73bpCEWnYxfHNjNOw4rc7O/2HXo/Fy5hsu9YX6tFZLvQdi9wdL6M8uWwdmdCCPr/kHZ/IYrk3OpXjJgkmZshQ3kCCAxUPVW4ISQlHMUdL9oJl55rHQKTLGSvidD3yxiEKj0bIHqBjdY4TS+uciINADEhHph2uR3lOGIFNLkJAEbuYudGydEAtFrb0iFHSRSoJtuW/YomgjYKiJnqNK1AG9roIU0kNpMRjqNbCfEg0ByU49g4BwMr1qpbSNU8mgMCtlJtzMhrLcZNxr2O/TqIGAdmY9y8so7pzSPECSMeFDciHgjaeQyl4M2UsK2ABSWpywn6z0CU1wPSCjCLAbQK2e+kdEA3boMbeRjEjdxp0WiiQm/YozNkO+BiNSqzFrTvgHgbrRYBWVrWd8eLwxQHKkXvHQosuxc4+tbnMBZZ/aTPrESV3BCEgLnGu9B4v4FPjZcbMssN2Qhp4FJ2vQmpLU8cjrHcvKpE5RoIMgrzzvNPIFOS+nu00zepJoE4S/W8lXxTIXNJj+keRvWv5iv8WFkWvi3KzMIx5AbSpKjmN7J6IiiycCn5h0jyA3W8KO+fYZkYQIY2MQnvkQkrTeuS9H2jMSaRYSM1g86YZSsHZkBqg4pX5+GZyvhNzIWqhaB5ZVGnxRUOS0Gj73miXMtOfUk9vc90QHo/Oc/B2cWHHX5jUXPizhexWJO0k2zXA0dfx9E3NlUfEhxY7OkxnUkFrc04YdF6uFrTpBXqQUjOXX+Oous8SspWeIw0rsgzk6AHS1MqJ3HMGLRnBFIPJeyflKE+AKxWxitqrbR/baTciQIKoJ2pgmtLzIsQ78ZCDAM+3V0oQ4xE+GXHBZKW2pvZ4vS/Z5K+zsodNAe04/isbMdR9SKxgNX4VlmENmQ6rRLSCJisrODgeoN/Ht8NK6MWe8dTPxYAHwkZWvksQXkYqfYVjUqcFIWpeQpekarepQyz0s8/yS7oM9DIptnJ2p7API5IyMesyvUfSYW1ZWRoKoWJznOsNKBZQkwJNJkVwJjOIHoN8VooxpJaXsBzyMyVAM8C7jDb9cCx0Dbr1uXupvAb0p8hl7DFNjM+gkxRye6l1E+LWifhHERNUBI63kWZm6LHiISYGBkBwZ5atu+qmrILJgZUum3nfJRr6ZyX4IZ7wKy9QzMAPV9JE1efidAJNayy1uXbQU7L57JanYjtsueB14pPoFrYmqqOG1IYuP/gCmYpIhBjlqLzGKYe5QQdOsVeCSwEMLz139zntkuXCudiXqHMwpVwslaY1h6nhJnSwAlB0uBswJEZjRYrstU2AQC041dmCMJq02JL0ep3SUTKEwX5cB0i38QjO9OOHOCoSUdjvmtyFBC0DwRq26LQZAY2ZsCoAY0jOMQS78ZChlLLHc+Cg9y0KVI1orFasb0wwIZIW1FaGcikqs9RBDEjr4w8HBEeQVh4a3brc1JMas7c/YwVpoAEI4nhzYyta3opwiuzSVwo1TKyeRl1SKP7zioisynxJd0JwHqZtkDckCFQzUEU9x3wlHacsHo80oV9OtmDAyPGvrW9oBlh5esBzUFgdGsp6gstY3QgF7JXQc7OHVRGSARd1FJSL31SLIyJkwSaJYRRBDcZYVbmpNg1TKtR2h+gHKPuxeLiOJ9dq9xOBOjYVdDKCNH6ix48KPdeqBr6hCC9PXT+DsWo3dAltCGmHdue48gBDrOq8XC/H0dnmz5bboCAEkKbsb09AMglu2G9HXw7U6LawqyNCg/iLgDJ0y5DyVeiUp1psbzX0KD7GcwyXMIuqUQq+zbvY4Gna+dRBjlDxWNcNBm1xFz3J9GPcBNxxrA2fFz9vQjedLG7rkL3E9HxBiwUafZrC8NZFJJzCq9Xsc8XZ5pizkp+epPnsuhNWlpnq8zbCbOsM1ZS4bm0TweAAh5VFkx+18sdy7Ulhne6r68rsYSBZN9ZCMWTMJDvtQsUlTGV7X049c4LU4BdDhwLm/foz4XdzEda5bgyKl9QkDoFn+g2S2huZY9jbdyBCboIrJ2+MmiStSQ7ynDoFXgxmHf49mpU0gVWP6GVIxkDcaPxTAxl1vhclKOd4ikFhTySfGhsZ+A2o9k3Q1ptMNsbvU0gZeEezD23Mvsi2mJ34UPLSKCSqrTFz5LKRChAQDOIKEq9gKRNh9gGaOsurFO7EZImGrNxk/46K7l6EAAK7xI3JISKM+tmBnAqXmCYJqQQXelrHIVkN6QDvIBPRpyKYjfunyFMZiL6G8Xy/epMX6stMp2HAYqBnKlvpZpWwyXAmx2HiXQKo1nyebMAQCva2ESrYzkzkFtwO7ObWe4ZD6d5vtR+B9nuBI5DsM79EMXDmFojQRXC97wOYs2aIGoNQ/XEzNXT2v55V6nqJCxmZpnMLr9Ai+bYn8hF1k0lRAGcu3BxGFdPU5R9I0vLQ2qzNApi3dCf+sXN51hGS/qQZS2+Cy37opb4G0XrYeGAeyhV/wvW4j0iDQvs2lSdySptScdDs8+i1zBO4EBj3oXzI+WSzhuXfczV01TbyGfOOpFPHyqxPCAAlHKCYF4FaWhXnXMVDroilyEPkVYeJrCOYYua9ADYrYpRs90JHH1RjVmt34CBQhF9dVxBoFQ1hiAKyGSLmmGzVGjGiL5AunelEWUAvMiqJieN/LPu27JigRRJWP02S81EABClFibun0lfjplWweq8DiPn5EVGONjKdpMWCCTkaiA0G6pz0BCh2S9PwjjNkvFZCWURqfrUKkbzSkS7LhxPu0IOkCEKr2ENc8xMCAfI60lnksQpuxfT0YrogovqgVFjC1FAZrwv+wBpv372vgBI+rWAAzdBsjoHsxOeFrqUjFE/nAwqOQ/Io4B2rUG7FkSFW3lhkDtItB4JRZuiuJxGmiZeJfAMaPZL2T5tyPfiXdDtuJZy39A+HebJNFWDoEDObwDiUTPqmZw7xwPZncCxyDKXXhv2u5oASWX2Bbj+QgbxUH+2qT7tZRsU7kJfr6XZlFg2tayK3fOVxqCza+s8FeRO9GxJE7BIz9H5AGzeRvVZq1oJ8RSoeEXGgbQMaqzvRtaMRNYCOssaqUfRFs9KVS5zwFFqbgq3g2R9V1FaLVbXwwhE9s9dPAz35JJ9ZG1IXE1rk33AMFheb4uQS/prFI+r5mgWqUDnTI/DKrSzAVf2AYzL8dL+RjNUdh/0vYwgNwn1lL+SJg+lX4cdvv+971DPZFcDhzcpNvm5qUY1zSUNXVS1R0HqC2LsiHk4kPRMCJoa00pVHkWk1cYXlNw75Ck5kMbU2dxyRqMehHMXAcriZ3glqS3kmSgTWSfD55XoKUaJ71v3ClCdLzKXXg8BpYuZcTTSL8ZBTUg9kXgTsygis4jYKAlJKP1HoitkgxKQgJyv6C0IowMZ8WB2EEirwYlJl+Mnxmhf7nYmU8WsKDUZ7apyC2O5TrM19cRG5NPwpPZFeBSbVlcWrXZAM4GXauW9Ytm8QA0FcyTRwY+COJssHEQAECexhBrQ8Iu0KC0wfCRk9TNHHTMhB0dugNHXA5BYlEKVFJ1DUIEhQA3L6A2znIF2BEpJGv/kDG5LrQvvYEn67gIOfQpseztrGcgEWF//Gt175CplrXwMqDgGJUSBDl9h80kZLKw85G9193Pfr8W/QIn//Wmt52ILvQlCjFm6z+7oLIF+LQeXvJ8eKFoJP7uXY7U0oGp/1kgo5c5nLBWh5clfx/Kozr2uWak9AetCXk+pq7MxBoKhZSc6JcVcaV8WmE2rc14mVQItC2PQVeT6eZoFQ20q/+yz231Ahcy2tGurXqzVuszpZPS6+OClEECxuk/tO24iXJJuYUqueo32GqMIaOxMbwPYbcBRW13kZl+89eTob2s3iXkkBiw2b0Xfi9SWObI1iWniosyQ/pQKEgQRB9kB7elaPVQ4AxkBzcEWNC03goNG5UpL/YY+bW0bbWUXtBuVyZzT2tirb/3zhLI4m4PsNzk3hDZGhFlGs19Z/0lSj0Ti/bQSvG2AhQb2dPXPErWNosq5QwqAaUAYaDay14g4wKGSezcFvMAAjUoBnntiFl4xl3AvyXdg2Ytmfysew6QVz1DVtGXWTAFPI5cB+SzSpMlaQwqnM9tTCgTte0hj+fztHi2e0/Ma3Wq6F/39YNX9PhJ4bQTOsXwviUH92cPWLjJlud/aVu7dtvX7jELesRoOYDcCx2ZeR02YzjXy2eQ9rsJc4A5WMT/qp5c+aUnLyd1T8NAHrjid4zXqegWrWam4EFmtKISeHR+oVIl6Gp2aF+poR6wfZz+TYcQiMVcgpCpaPW7NYdj8V0tx1l4Eqn6qlp0J2irAr1stfQeEM7DPKOSJpoNV1FYDiInPgJIS9cpkLl4caYs/JpDp4FHtw8M1PZcYwKuNDNkaiUzfvJZ6Tg438C5v1ukNlgUDEHVCnEjtS0gpnqCxqAxClttPLwaTcmmtOnVZTzAGEAcgRjCSHksVpTvQdh9wLEhpcQ4dr8NIUq+OJS7hR02xbxH2UGL3ECjlog8IKhrSJjFWgVpINJRUZC4/oWFD0E7aebXxJzg3QTkHdqIvTFpZGLrPrN6Rh0jKmZj6lJIRnBKihawjIWfWQovdu2Ii8Eqj0mm5oeMkIcwIPCk8QYjs/VKlP6kQqjkSeBy8C1mcSuYhTlJnRgwH6duaR3KMMMtAJvGeADQbScVuoYAoQ/dXFqO3WdSubfbZw6wFpozmwAS8OkLau+J/90LGUUDm4HU77Z4G2GNjNjUkqb2+YN+pDOb2Un0Nz6wD2fhW0YY0B1Kp8wG0Ull3xxA9B0PGIQDlQUQkoUoIQKPtDNtWOLhZKwOf2nbHRiu7Dzhuj/UVpGaaz/dtKg/CTOJ08xJ6HEYuT8NF7/OiKCaJ6yN1vAM270TdaoYqDwEnZa0Pqus5GN2QzPlSTStqz0ya1PlT/awmeoslLEF9g2bbuT6BTfgWyKuES7bJOA8ux7BDMrQLuZDDNbja34ueRY5JWQRbZG6+el7mrRlxzZnBK42AijXPsWtoCt8A5BhKgyWlusi28y+wdz5Z+BpOKDPD7X0o4OJ9XOpVxOW6SMF2UA+p59kGwJsgWxf1WjZgatPNPOLDbLsfOPp6jr6atLNp8A7n3t1cmxMD0MbA1CmZFvm5uZlwpaHcTKLdiJwRtP7BdBmmRkSwB1qU1oJUKlvNLbebk4mQ1/RYTXC3nwlI6w28NyZzZyocYLwBI2yI8IgmqYidDMyMwBs3SBrrt2uxm72pzstbJUaA2Dqvo2SIMoN0HCNQwqegw4lIJ6RF90Co8xMQwrM52LrHQZkR95fuWgKCCUY8cpRzDmOZexImCfFWVFkM8qc+E9DuiWjXykS+0UHJDHkXMd3OASrLdxEPitzda1S0NaN5ILP1gLQivUdKx/oSIoVplpAkSEYrutekWb8YQSbwCawAE/X7kvuUcganIBdhh4HH7geOrcymuS3q1TFXS0KFC9Esg3QAA+rHkysFFx3OppWHyg3Wt8vNJaATKo/GyUio96GLEuMAb1AMu3Gl/wb6Woqk3c9brcFg9hJ9ak0UoYtWe2QG/T2OyocxItHL8fscxkyaHgGQBst9jDb+pCJ+vTs80AEHEIm60oAPGk5aXxE/5+rz2kybSEpIy3dKk6bTDV7Adr4HhxC7BGptgh6cjO3wQSwehzlhrprVz2TfqRcUKndjIjXJYkE9iQVOLnO5TrkHClqzQpahCTuz0G33AccCorNTs2IchxGk1rHJ6gDqL6nDlyihR9anIriuwftz1G/lagFAQaIp+0srMnoQsNAiICIjNYSkqR+mUlkbtXDLgKnV+pjS34KKy1vVZAgfkBH+bZ/0u2wTvHSbeU5QZDU8sYkIK2OEg6vIqw3SWqPpYNVljMyTAeJGRrORtM6jRWhUVavnkFca5FGZPeJP75obAjwbZR6XasCEoCXAxsJlAwEiIAcEJTnzWOpS8ljijsQVOAOeZQrT7EAQWgHGNBbthfRxZTQbommxzygbl/8XwlOyK4CFU5ZyBuo0dLm4kHNjHWCVhQTtK46tERN0KBNZqQARqGnkNsvsQ5zk3t1Z6LH7gKO2Q01v67yYO+lY6SSeNW63RSI6DtICI+/XsEX4cyizmgdh5sldWunULax9ka3PezZ5VEIkYiBOlaw0zYR6AdSKzJk1tbeZTJkBKeXWGpcQpVmQNaPJIwY1BEqFF2g2EsJGKsIzoABCBQrW/UpIUEuJdBc2AJVW11kfds/JgQT68PaoRsC84+2RAGoyrymQ9tnIHa7JyvwtzMiRkCODRpXXxBWAqMfBWebtZEBWComegxTQMwhRuRnrbF/PuQkzRmMen30P5tn2H2BE9u3sCtvdwKHWV5ACQN171C0l4c9mraa/1GOI5csl7SMZbEHEQkjmUReoiqsKr3NwV5+rbYI8uSxDEVIRGiX1OKzJTJzJeWTt0znbQ17KLZkLuTGbSUKsqj0xmYLbBMxkLgunBU8oc41jBMZjYDYDTaagpkFoIng8kmyLVY5qaBEPzEAHp+BRU3gg4wUqC9MkQHZgItd6dQWw7mSVyIphXpNeY+23SrMECgF5tSvmAgq3JNPW4GGJKFfLbSxVsxXiZGC0P2m8YdPtZJYuR2viXPQjdq2DFdgBoIaQVhU0vA+HlBjIeNDiKc7WNeOTSPqablTAoZm1zkPN9CchlsxKB/h3ZlpldwPHZsVuZv1OYKajqBeVsdi1JQaRxaHkgBD6LifkHrasg3dMj+ZRwJ/aVD3ROvUOUW7kPJIb0kDE55lU+5hXtomXhJQFNNoWrBkGsoliCha1lJmAkprNWRobMZfXVUNBJt+u4vA6GzRX7l9dZyNr52sv4OlYl+Bbo+YMANokOAthSOodIReg6TTuQY+fIPXcVGFqoG61M67X4PL9yNwd9t8X1RqJRL5Kz4IQpwyeAJnIWwu0Kp/nmZxMHgcX9Mk5qrfR6zFbpsYFUTtT8MwKBRletZMI0t0JHDXPsUhBuuV7s0xfyxnEMrWeQvVEZJbaAcAbBVOroh1vr0flxjU+QAHGajfKqILCj7iwy0AjyDChPCYPSZqDjNBSmcy+GWAwZKElBcLJBDydImsfVTpWNA3UtuCcwZOJ/B6j9IQI1pmGwTmJ95FGcmM3ETSLMtulCVKpa6GHEZioQQPOC3k4Y95NImAE1M2LaaoKybFMfKdpW7q7R0VOyz5lyPGJChjZEKrqOhupGacAOEidS8viOTLg4z1DufYOEgxHH5OWBxKPQh4WAhppFZjeLet7A/IGIegUu9le+Q5b7eQeZjJPZrRfQr7Rrcq3tVmqmq16tiLkrVLb7kfho0I12GrnZFd2J3AAXfDYzPqhyqK/xwir72Dr1WFW1xuYkEuJVmkOTN1FbZubR0FVfYWGKN6bwv6usT1ZFoPLP1GAaiimXbrilEsbQtM3AOXJzqKiNG2DjxzUz8GZxR3e2Kg+Jmm2IpaPYyIqJfGoTUUvoXoQ1rCFsmR1PPRroleX2nGNvzBRlHsYAWUx2JPYu5Oj6DS00alfL1XnZh1GVcR2ehHZvi9gsaemP/XQWZsQWahiXIQ1EJIRlKzNirgDPshQkCJYZ0Bpq4iigLVMimlMDGTrEog6y3Koe/sw2+4Fjs2MM6QZscW4VYxIBG8luJVlBqI+pXzx6yLSVG227timaQBK/YofTziLOBX9AyWpNJWnH5y3COb2U+E6vN2ekAJoJiIwa/YnT40aG0+ZVYOlT+SUkA9uVNegekrlBJ4k8UDsNJsGNB6DjCvQJx9UB0LTmfzEVFSNKyMRkCl4hKkCgbZktI5qLvayEAQKBNOZjLq01PfKSM5Vm9/UA48oK3AQgfKqLNCqNiQ3wPRYAYw4MVk9O8B4tayHe4XDCKlwE2kUkMd2D5Xwp8ypEY8jr2iYVYWjgaWvqgzqtgeCNFEWSXrlKYQg9UhJq7lnNeCzj4zc1HaIIOzIAw6zRdLzysgWh2zQcxfJ6yzk7/6m0k7fSC2Up9aiqklz4yX2YWX0i5vtT7pR+d34EOvuTVwGDMWZuOBSx2IxP/mwqf4tNdcHYoGx8j6UNEXYlNhbwKHyRJgVROBAYf8sjRqgDXfnvpNyHWvBFup9A0V7Yp3B2xY0iyLDB5w3yKOi1fB5MVDCUv9g0vU8knYBeQTPUFELsPbRqSuCQSUL5p3AtMVinsp5h5n8i7OKSCV9D8nvUWtYiIE8blz9Sln2QTMqDX8UNH2cwg4HjyMDOPo8R92fo6/VQAZR4wrS7t/UqveUkQYqGzcvowpT6n6epWExYNLt7NoziYPTSDkN82qU6/DhyoB3E7NZJXGaESbZ57DU/TAlPGhKR7PafHD1Ia5fshb+4slYR3jrH2EDsZGzPCXbJE9PIikWa0TJyUF+L+65ZFs6noTNx63PywrZjDRMGZjNPNQiAOHWEWg2AgdCux5Baxq+ZA0LTAdi/VD0u6GUJRtFRSLu7QUa8RQtPOwoRe32ICVXJ+QkZ5hqn9SJFLpFrWsKMwUWnSoX9PW01vj9RC0jGuDO2gKUdh10kNOc52HT3XaAHRnAAcyDR22mIE1JnspKgNZ9GeYsw8lRKABxIJGf66INM0mbCqvJnqqrOQoA+jSWJ2Fa1RSseRq9xr0mMDLtQWjl6SX6gACeSBm/dxWzzxCjhxz1xDDOrVwbJUNl0A8DeT5dy6xPd+hTP4YSsqQsC37UAOORAMXKSFKk1oUduiC10M0L8Ug9PM7dWhfdf17VRdVmaTg0awVoghKiWY5toZc3K54xRgeB/HXlf3SaXKPjG000Bw0dqM0IM/IQsTbKjDgjiWzJ+AlGGkuWTFLhkKFQGRjtZ8QNoJlkFYtp2JK69Urc6APM62709UgyiNraVpoF0lBb77n+l7RDwGN3A8dWJJLKzNlIKcuUAPBagUX7UxPZdqqIPQJGEcRAilGeGjmBtONXpiBXk6VC1UhR80JMudiuq7dhwrAxwFGftplA9iSz+Fj7dlq2JkyCZF2m4saLFiGARiMpI0krMgW9beUzt8oPjCWApxiBWQteNJfUZoDo1DHxyqKATGbQ3Y4BxiOkY1eRVpsiv9cFHaZS+WsVoXksnb5M8CUCMXmaIkjNDI8i0h7xInxQ0gHpu+reUn2e6sqHNiNuZM1AkfQ41dDAyvtBqMoGNEMyzaBUOA9LoYcWcn5VF3gwwI0AvZGdNqd2/HXxNJoDEjpa31hqCWSSc6C0FgRKMydAyVF2InnuXvSQOcAUw52u54c5XNndwAF0weNQug6gxI+m54hx4WalUW7puUGqS5AQgUVboI12w8wIu+I9+IT0UIBC9q27ZuhMEfIYvTkA5zOsx4UjXp9LsSrXEIC8BuQV0PqaLM7pTNKz//51/9wUgxCgMYKSySg18xQjaDwSgGEuoQoAikIE8MoYeWWEPIqyINjCBCV/tSXA3Pdj1zxAlLlt0jQyA8HCPJKFF6HAoDxAUo+DrMgtdglPhjc4di/MuB+tISH1/r0wUYFMUuNS8FZqkOSndWiPE4B0QBUIOtxayepZ4Zn8+9Q+KJ32taxglgtR6p6UmbV+ZD4kJ7UTbPcDR984l/4c1oOiqluReawMIEmDYkBcZqBLkgZogRwX9Q5zaYFv2ZQ2I1BQIRXUdVdloukM1F23wijZl/xoNuDAI3025ckoncK192f9oOHu+/NKI4tn1O1lSZOEcGADdHBDVKSZ5RqMR+p1hcLka7aJxiNgZew8h7H8aBrRE6yOkNdH0i1srFoJl5h3F5BnRWDhBnRxFOGTCbu8M1cETN/Ns4wI6HXVTEYIrkTNFcck147h6l0/kep7YwUDA43WMmUkt4bVJSl4hCTvaTbgYj3ASFiWzuoJXaDUMgUv9gM8w+LNqdUbg30u8xrsHkxJM0wlpCMisAnBdojXceQBR9/qojfzLqxaNjMYqlEgBZHAWkHaiz0BeC5eyVAE6vbWyJBJ9pqn914XAe5RxKnFz1Bmn6uZpsbEw70Nd7uBAiDqgTCM8APSuHG3mzIjjKUJcZzeXRSlExvkLOloaZEYy9CqGMBNBEZVSrbKrHialSWzY7E8B0K7VrVghIYsfs4KTEE7yVNFuI4bEZhl5VfcFZNrhrb05YByAv32hrRg4XgDaV2sALxsgLTwDIB7LV6wCOEw6nyQpX7tJWvSZGGRdyez77Bu5QhoSwL2TFgHQCzd3VOResasVt/uAF6jtiMDOBZwHUKSbpJdATTjIZoPbtvy98hAa3zFgrDHbuTA4BVr7FPISsoAWlU3NgxrtuGzT6csFeutudi62+rpGVqUMYfWDUuLwmSWiN3F8AyPLF6NqRMQVgLiSgTlY0HTFvT1/eJxaXEbYixkZwgl0xEgs1ya0jWrbncIBoI2B0qrDfLY+pWW6xsncg5xQ7pjOTkKFq/BZ8VE/zyU0JndCkDl9OxVtXkUkMcReWweYveJzxUI1Iu6/u7ESzD9Rjlnn4GrM4Itu2LfQxnExRrCSN29Z28UMMJUro2J47wOxjyNJMQ8aVdzB40FxqrJQf9z7AA7MoAD2Jwo7ZOkVmZfdz/PQWXLVTyeqgxAHz+CkFtZ3UuqXF8pSw/+JIM+/aSjlGZTJDKQKn6VPDuZNpIFFmE3sz51nIBM+mQz9129gYa8hT9Inu65IeS1EagJ8hFUqcimo1DyzQDDmhcVXkf1KuNQPCuCD3AyIdxsPaBdLde+GZHXhVAKiKPg1wfMoBUBqbwi5KlNUrPPmE2kd8xK4S7UjPyse5WURkKWBuXuE7xOr1vY1LvzSW8Vali/k/JAEG/CsiJcXXd9r2Zs3MsBQLPKQ7AQ18KTNknmyM7R77kk3FKuUuMGYnUWqM6sHKZw5cgBjq2sx3W4ICwCptisTZ7uGoMTga3cXaXWxnhzQy4wkm5YCdw0rjgF7Cml4UkCoGX0GXqD9jwO74FpwGNPQo2ySHmFGiilPJ9cyUgkA4/zKCCvRBGH2dOv5gvQdfWl90hBSe9vOrL2ewIozYbkHq1XSbtGmK0r+CgIxhkACjoKgTyMqwlem8nrGQ5rHMwGJKMOKIdJqghGA3r4teBIxdNYFMI49yIen4Cl3SMAQYViBB2FaWFlD6j02hCKNxJ85KNvUR5UqEKY6UxAv570pttxLqDBvPgz7BQ7MoFjk9EJznUoQ08GKGbmjegAHQ76pTt5SmBkGRWZMuLB5DcVACXtusRdnVmRnQEI0liGgwq8UlnAaUXAI860EfAouMAMzGhqF1yf2tbK0DgSi7X9fQHeipAbVDd3Ie/kM4fC9NtHDrFwJxoG5Cgdxds1CVPaVZVjjwU02jXptDXax6quZM2+GFjZtSmchg1gCjMWoZsBLpfP0yGXAe//4WS19lWpuY86KyN/qxajcTcaAnKQxsvcVkKvNpeQpCK2/WFh82nseAYUlQbIPVjmbnGb/d3qU2puo864DKHKnWwLUrMLuQ7/srKKbXr7sEpNE4mZBSqkaZvFAdEbk0cRuZGpYM7Os3oXVbMeY+jTSnnChhmALJ5GGom7PFsLiA1r/QPr04/A0yDkrC7mNA4+Ka00+tXzNeDQ4UdMqlcg7oZhCQImOZdsdtYwBnCPwDgF1lkyaUxoV2QiWx4D7bpIugUMZVGGKZBa5XJymUcL26/9rwqskJUb4XLNFoYcJqpKMoXep9pVRgxvp+if1UxDSCYCRUJGIzqdaaXK1ZCQGEgrsTS0zgIMdux6NAXMC+p5FB1F7ALQ4KT3ozacci9kh3odRxZwANvjOixkSRnkQ0cI3DTFdTdOBIDVVnBTTU6zJ4SZxuI+t0SrNEOS9ycl2+yp6XUpdk+rtBwAGIS0Km6zD3+GPu2bEeJURzHqa/JT+YGq2ZCPaaAMSlU1ZrVojB8Rb0xfj/J500qUQdRrEWnVmt7AdSntaijSeQ01OIj3YfGW1HQoYatDjMrYA7hcPCSbTdsNCeRz9L9LdLwm384k9/Zw0O/aQ4bZ/CKkKPlyanI5Vr1Y9X6yHiGdsKXazrio0luk0mvY7+ZJWFii942nxWtvI89/QE/F7oAMy5EHHFtZHZrUIYt5HilJvnyRW2uS561mFZoAie2JJYImSw9mKgSjxfQclSS1dJ7uKo2p43IDCg4M5CaIO5+rRaheiZCvRuwBQfPB3KqitZ8mdSJUQ5mcNZUcnNvIY6rOB5UaVs+/Er1xFK9DXQbNrmiWRaXblHTSu7oeBpqUyudZZN1Wg73tbC2F8vnIRGb2pO8vRs+khdJ7JVX7tu8LjEDqiaS8ELSc36hK5V3kVXsa/nvlkVSAMDeAWoGFd1i4clQAx6IxkQC6UnQyUMmLwUHjWQ5Z+0UEfXySj1GUn0YaohCkiau7Hk66xQ2rf4D/LVsa0CpjLWXLCgTJfqo2IGgYomnZPC7HDK3wBYCGT0zI41hc7CxNjaiSZcu2OhZSQaNd1cHQ1fm7hxFFQp/HQFph8LhCP7t0YyWjSQCk2YA28RXQGB3kIuJilMbHRnz2vEiqyVFAvCWXs29yE1SeSMnSFI1mCWG7YO2tElnEbD5drueVOJeivU/c0zDQaKv+KJm74bDvpgpdKtDo2NzvhwdQjmzgqHuQGtcBwPt1VA11C1mKwoXUjYCquFOG7WRoCkOb6FZpxZoQ1ae0/QPkbaGVn3EK0TqYytQyC0nXaK6exrn+p3FzAhAIIRIygjcHEuEYilCrIWQOoCZouNCq7iFJ8teAVb2VAoAyqT6P0fWW+gDSsP/zQj9z3Kzqt3L4iC1EKaSoP3lJwjXinoSdrJ5lgecQKqBx76P+u51s5XGxnpB/rxXi2cL1DvfzYYkDmi34VGW8zEzEVTV6Ni5jrgLWSdLcCYM3DVEOI/9xZAMH0AGPjqnnsZAs1ZDF292Z7iFpXr1NIPVKWLRMoj1Y4E7aInfFaIL2GIVXXVLWm4MAgBw8YLwI4FWyxubnRkKqMJUh0s3BBJ5kxGnw1KVfgkDIiOVJ61kUADMGxQzOUcVZVWYisTe8oUxI60C7KudUO2VpVaqEw4zU+9HPbilowOtyQgKCVrGO96lXNGVvXFQrPqWrGKqwknxfAFzw5WDR0b1oChrlqW9tATogoOrhDggA6LRAJAKZQM7epxW85SLbeVeCrTokqXkM1rYF9blU92HdzW0n8Rq1HZnAsQlBuqjkvlOZmLkIwzgBiAVcbL8GMtDXyRrJonKtu8ew1oGmCeAg7r8PM9YwhAmgUXl7vRviEqZYmb0/UJnLnNtWSNAwkarYPBYVaGdam9/AxTUmABhBVKPVMa3KFyxchlXzlroSeGsAanVsZVMNkVbS1j2lVtKzYVZK0sMsF1KZUdKsJs+27FY1l1VKBBaQ4Pr5fIZL7R1YewB/GFjoYh5RFcbYddFtmbmrhzHgsEVulbx11qQOOyxrYl5G7V3Y+ztAdAigOMzZliMTOIAueLjKLmwestTCsLqtlKVrrdYlZRBaT1WKkyCLOEOrW1uuairQDV1gINADtyz74imDTAFagYoRh1ZlKZ8LJS04kZ6foW4K00QJTWwCW5tllMJ0Btp/UNWjQdKYbQLaCGqb8tRlBqWAZiVoq0RGSFqUZiEVVd6TAoxoHlh6X3B5vTmITt8MqvpyOmgAItdOEvYQMmhqsvWS9qR6box5Gq4KDvONgvr3BiDEqRLmPtOmH2ZA9inNi6pt+s2Ga86CqxCk9jiAypuoQhHzTPyY+voODFHMjlzgADb1PA79Pg1vWMOHnhvrN0nWR5XevIGyFIHqdqxDg3NDXSdEvRLzMoAuVi2qonWOhMtr/ro9la0/KKA1KOQdySlrn4yNqZTcb0wkm7CyIucT2Sv3KRJoFIGWEZARpow4ZuSJAoK2P6w7lnFVd4MW2qtVfg2qEwkzdAr3XIKuoGEpYte8tOShpHwNlXfYBwzzoPoNpzf9jquL2Afx+r7JesH7/VurcRP9/XaITfv/+r253D8OJHWYu5W3sQNAAzjSgQOY9zwWKEo5wBV/8qQKqu+IACTr4nxHjN2bMymBGjTU0HjbZodkLsrPMuFcyVFm70maVuTJPdurIYy69sEeWEFCBYxVvj2BoIY1zpnMiisOgNIUmMwQN6blOlg7PnObLdgZNeDV0jmM2oxwYOpP7jEASg3CLCBNCMnbHkIrc62hTze8Cq2FJ9zhOLwc3UBzlj00YZOOe+hSFhvNNGxoQnm9Cg9kmp2Q1WS1OPY3G4+pT3df3KE3IGkzsxDOFj33ic2ed1B7HHV4Yn9bpAytAGPO29ghgGF25ANH3xYoSoHqaWYEVa3vsCpaBxgrzy8uPbhK7WWW71s5AnEhWLkJwLIDAMmuslXTqjZiBHfj/YlO0IInfZ814zWxUB2/11Wws1kFnCwdwfo3IWlHtFBib8lcKBk8iYjWJgDwz5FdIcs6WIrKg5ttHq5+loxCgNZ6F/eYFDxIu6ktspR1qnt13e0jGNlI5N6JoG2V6ajJR/MIknqGQLf8oGfOs2wGGP1WjJWXMQcadolqb8RCme16HofZjj7g6JuBAwCGtuyvh1XXVbToNTjuube2IEyyLIVvGrZYg2OJZUA2AnLFBjoB1siHTeNgWo+pEZTVQvEFaJ5EW6orOUs4AriHRE0D6ylqNzNF1orYIGX0AErXIsiiqxSTcSrdslIWYVcwjyOrF9Wo96ZAMTrIysuUMASAhyrNQSm7D9NWjtNmiKJfBmVJyldaDEJDLaSqFN0ApC/jTkk5i1SuT0paRFYt1MobpZ5cvUjA9fvr3zf90KbHUSwkQJexGjR2mLcBHC3A0ec6+inaTVK2nSra7RwjsTRuAXW8D8Mc6GkwStl5GluHKG3AMyM5HQtVrG9H/96pyEQrzKuJN58dywxCI990RyI/fzN7eb1xybZ7NqKUBUu1Z0VWlAyk7f8AQCtjKTGittfzXhfRnsIKrFqeb+IpSglSIyOl/6QhSWfearUQO+nlOS+g4hO88pS7rn+t07DraH+r91UvYr9PerxH37OoznW79SYLydAdCBrA0QIcQPkCKr6Dbb6FjVSow5G61WDdmzSbh6Ixt2VjrO6dg5Z3F7fdG8AAIBaxWB7Jomg2MngqNR25KWMSrKzbrE6LWod1Soy8OgKNImilkQzLxrQU57Ut2DwPu8ljBIjLKEh1/engdF7KrQ1+5HPD+RjjNurwAwSw0ilRVaDNvjI8CswyNkH3BZaGwx2JuS54msw8W+UeQ87CU/h2+plytVj7/MMioLDfaxAN3L1Gen/UnoSDwmaTAXvexULSc5HVIcoOzJ5sZkcPcJgdKtNSk6V1I2MrQCKLlQEfX5izlNqTlt2TtCWsvYSiD+CSKmTy5rbeWRvCFVhmhZRA7Zv3tIxKAoYAjhkhqbBLR1sCRpom+BQ7a0CkIikhJSuC0S7VeNS5bv1uW0GBLCTAn/AMB7U4yyUVzAyjdWy7hYvKPLfKe/JQxM7NFrApQevFbd9VP6NRAUbZLmsP0sJjdc6jDjtSdexF1vcu+sc1T6X+fZeCBnA0AkdtFVEKoJClBh6Wkwe8ipY1/WrjCxEjKIfCMzQR1GQwN4INVecsL5rSJ7c1vqHMiBuMSEBoAzgyZur9yIlJi37vKp6BNA4IZEOVdfZHJGASpFlz08h521hHE7dB5q9gbRU8asDjEWzifT1j1p/kLNwDaT+PkFj7VVSchfYAiVMd9KxZkrAxK9wFNE0dgnRIA3TmiGSg6lDEwcs8oJqjMLPuWLao+yDRA4jynXdfsxm3FLt9UzvKzkNwFFtlVwrZ2SNP537vnd8Ot6MbOIDN+Q6Lf/tVtHZPUxBCrSpSEq6BgKTvy9q/oyp469Z5aO1FFZKHlpG1y3YGlQd5KNtYnw9uACQqD6us56nCLtJxAiZxdr6GSHQejfYWzahaAVQfJ7O+T0VmSVsARvXatBLV2uvZXBULQajVVnm28FIAQ2pCuO/11WGSZ0AMOEoaVQ5oZHbPs+gDRupnOgoA2DalxUKVwrJtl+EoFmRDtl3RuoOzJ5vZ0Qkcfb7DXu5J0vuNf9zzcE+FgKaRhapAY26/NY/hCFko4whutPFOQzpikNAckCd0HhUPQxSgNoFdztXCF0BAI60FZNWHUJsRJxkIBF6VIUchkGg72iSZlDQTTsP+kc0pIQmtQtDalbZ4G9OZ8AopIc5GCFPpnB6mUaTsCoI2zzZM2gIUWT22qpzdMlY+4EotTGbdWhLTW5hXYMSm148o11H33txCK7EV38CoAGuRbbb4t1jstymluks8DbOjEzj6tp0sSw0eiOL251AWmfMWVn6vk7oog2USEaxTNgNwBaincSsCwF+nuWyK9tAt3cwjoyZBuBHxGo+iitOo44ITdX8HIMKt3BNCVU9nilp1q9fB365ZGJrl4l3YSIOa1LTGym0CUQajqTqNoQsU7m0ooTpHcuZqMS8oSa++K38dWOgRyGdYXJy4cNtt2NEAGsDRDhw1UbpocLXxDCmVRVW5tc57ALJAWvJh1pQzOEVQlslpIQCchB8J2t8SgFSAKmGaAec/OjUzdroE6dYFCw8IIWmxWwAYBA4RaEQWHkJAOLABzpqejVFieTvfnOfrL1IGT6fAZFLI1JxBMxmjQFEGN8UmlhEA1gujqt/wStGKO6GpiNHmR1XkLlDUTW6AsrBd8XkIzqJ+j323/a++5rUW2G1unLMdsNiFQNG3oxs4gK3BA4DJkud6dFjWxXsr1MpSiJRZG/8QkS/Q0JIs5FAAwOo0iElORxMgnQbHKN6KeR11upaJQMFCANkPNwEYNaCUQLHqdj5X7YteFSkXMtW8qo4uRMIHSiq/rxSrnXL0PqlpataeXmIuG+KS+Mpq7qJ6r+3X97MFYCwCgzuks9YR7FlsZgNwAAvBo/P/lpZT0Y8TaqwahpSFKORqUWSJTWjWyiJr1WuJQXpFBMBUkbmRUIYSI6j8HAjVnBR46Tfp4OJg1bITrfGIJB6HDTWKOr6h3QNaW0Gw1GqMpQlwNUWM6ixCMM9JP48XnQn/Qa22V6x0IAC6JeXV9ja0GkGFcR0xlxGiJQTpqC7r7f09m3gXW3gWi7/3XsiyyT5ukx1BILHIBuDYxDohy6EGWdfv47rmBSK2ytosxkvCGWCdKbLgBisjCQkg6SvR/7vVeZjlxtwS5Vo0a8NNEK+hHu1Ym3kJFqrUsmzfhjXDVC1s1vCkPv+5LAYXQKgyUnOLdDPAqHtV9Gwr0DikF7EIHAbAWMoG4DCrvY65vx0CPOoxC0aW+pxaLrUTROCR5mIB2LwTm9lRpqcBXiDXEtCwKzYhf0LQEMfa+2VtJmwjJOMsSU+LQMC4KYCSNZzSSWJSUZrAs1nhJMwyAyzcCNefNUFCOi3h71wHQLgUUtDVz7+lpsKPtzj1SYte3y5g3NGpzqMEGA5lA3AsskVcx5KehwORuuj+mrnn/aSNgpYVdskv6p1oV3CuvQxSb8T0XVH/Zmu5mjDnSkwDDSsUq4VfdcMZI0WtDZ4pz/rXyD5T3zJXbYArT6K/fU9YNedFWIi0DdBYaMuAxgAIS9kAHLUdiigFsKh/ByG6sKpb72ALAQ4UlPTpGYMIxBKDQml1Z1Wh3thnJuMo40hHLSiVIkOfyEOUHLWaVhEmTpL06Tgw8c9FbQIObsCzF9VnckCrwZGCqk3R9UT6Mmp7zRf8AuFVPxuCbQBCwjxY314PYwCIO8QG4LgzzBaJNcw1vsM6alt/DmYlTkUrEQDkwNV2EDIyaOWsKklNoOpzV4HS0zPrUGbTVFhhGIkHwW0qIQSgtfElEzTXrWozcwl7+b0oNrmbcjUNzGaLdqvU6VJewybbDmBxh9sAHH07lLaj3/inb+amW8cws6YR8NBp8NCZo+GgHC9Mk4wiWBv5HFPJpkhToDDhSj0G0Jg6vAdY5OrNgYQwSQgbU2DWgg8clO1DENCYTETTYbqOkehM0DRKbvae+ha26GfryLpTz4uoMyqda9LjTTrXe3NguE0kZ+fvA2DcWTYAx6FsC22HkaBSVp9RGv6giMfUqAYkoPAd9joRiG3SWpYhSVRCGZ6hGwbpXBathVWZuva4aAuPYZWXrGlRSZFq7QogCte+etLCjv7n9VPfHmcBwDMicxoLO87CS34HLPgBNO5UG4BjkS2TYTE3HJUeiwJ8QBCR/J401RlDSdfWP3MGmogQtBuXZlh8NOFIa0OiZG+oDQABuQ2uOA8zGYsQpsmzJaah4HYKzGbI01m1YEcyU6Vt9ZzUmzCi1KpGAUWpStnZ01J4pWrfOnNGFguyKND2wGIXNPE9WmwAjtth9QBrABU5qOlZQElRmb3iBXM1aPRIynosY/2EJqs7IRaNFqRLlvzUQ1kWpa+v4Fw4hs36PtSvh1L1WxSz8x2u5uac1tfA97UYgGug2BQ0hlBkx9oAHJvZobiOHLqLQr0OWXQabpAymF4GjiLJ3sSjoVkCIcF6d/BK7ABTSMm9kc7pqndC03Z+RGLmouKkquvZItM6GRvMtLADeJ/o3Cq7keqXts9vHNIG0DisNgDHVrYN8Oi0GrRaFqArSQ+aj63Tnn1JiHkfbSoK00Ciywjd0IkAl6zLC1SGHmfML6qgIUetxeBccRi5s/+FnoRtdyjAsH1vZbdXlDWAxmG3ATgOZdsEj34FrfX9lGHW0Nb+ED7BJqhZwZcWxDmw2HEB0IZqO6z3px1DC9bYxiLWw4nqLuDWpWyMCriU16iK9urmxgutH6JsU0Nxu7yMASB2rA3AcUdYL+tQemLqIrXuYaxaiqxdtLzEHUXx1SdNXW9BVR0Kea8Nsqlpfb4EKMQsTA2avQO7j4Go7RCgsZ2iss7utgsaA0DsOhuAYzu2HW2HKkrNqApZSihQN55pJGXaVBxGLcDqex7mnZg0PZAqK8mrbsvByYGLmgj2loDKb1D2HiJ+jC1AY+kxhX0bAOOIswE47gjrld93+nfYJsZ3lBcAZHCuZq4vWl/9lvwGJDZWgHTWaieLwl6w1hlCVL1fzjPMay/6gOevb77It126vugcBtuVNgDHdu1QdSy1vsPKxOvGPlz12bRZLTrYutO4V5WaVBGffnz7nbnwGNbSzzwO+1vbFs1F/RlUELZQd6HehXEfm6ZYb0u9yAAWR5QNwHE77VAVtB3Pw8DHQhfTe9RvIZRCuqpR8tx2cyeioKBt+PojDA9pm+gz7pBK1AE0jjgbgGMZW+B1zG9T1XhY1ysTigFFgl33Le1PXCICEMsCZsuYYH5koYGWeiBsytC6mnWLYcrdj7cgW7KdWpLBwzjqbACO22NVyGI2533U4NHTeXjGpV539ZCVslMJOSxTU++HK28mZ5eYe4hiJCpQQijbtlKCznUTn/uoSwDBABpHvA3AsazVXAPQ9TCwSehScR72/7UPwDX5afqK2qMJDJ7J795weO48qlECKRVdhoFGXRODBanV/se8LbUjA2AcNTYAxx1lFYDUxVtzoYttbh5Ir/4DUH/DwhjzGGIEkMH9yYH9kvd+389lAGOrCWS7cNrYYHeeDcBxW63/xPfX8+beB9DhRRZxH24p6XBq7SheF33U3EpH+5G7YYhZP0OybDgyFJsN1rMBOG6vLQKQHngAmAcQrZ71sY+b9bKoeRAHiQpEUu1F5DkPQ05x64V9tEwfG+yOswE47iirMy7AQu7DrBPC9AAEqHpb6CAlpCTVqqnrRSwKc/zwaRMA2CwcGWpIBlvCBuC4I60PHkB3QW4Vwnj/jp4waxNgmOMsOn/bPByx4y9tA1gMVtkAHHe0LQIP/9s8gWrmM0wrAJHd6XZ90hPYsnZk6Kg12J1pA3DcGbYZcep/X6AwdS4kz2VgNt3HwpeXrBvp/H0Ai8G2ZwNw3JlWL8StQhigF8YsWa6+eKPtnKFuOwDGYMvZABx3lW3HCwE2VaLe7lEBm53PYIPdBhuA4662JcOY25z9GIBhsDvRBuA4XHYoEnWL0Ydb7nOwwe4CG4DjcNoyHMgy+xpssDvZBuDYKXaoEKbeZrDBDrNt1RpmsMNhm/X/HEBjsB1kg8exU20AisF2sA0ex2CDDba0DcAx2GCDLW0DcAw22GBL2wAcgw022NI2AMdggw22tA3AMdhggy1tA3AMNthgS9sAHIMNNtjSNgDHYIMNtrQNwDHYYIMtbQNwDDbYYEvbAByDDTbY0jYAx2CDDba0DcAx2GCDLW0DcAw22GBLG/GhBosONthgg/Vs8DgGG2ywpW0AjsEGG2xpG4BjsMEGW9oG4BhssMGWtgE4BhtssKVtAI7BBhtsaRuAY7DBBlvaBuAYbLDBlrYBOAYbbLCl7f8DbkUvIKFdJGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to visualize a batch from DataLoader\n",
    "def visualize_batch(data_loader):\n",
    "    images, labels = next(iter(data_loader))  # Get the first batch\n",
    "\n",
    "    # Visualize the first image in the batch\n",
    "    image_data = images[0].numpy()  \n",
    "    label = labels[0].item()  # Convert label tensor to Python int\n",
    "    \n",
    "    num_channels = image_data.shape[0]  # number of channels\n",
    "    \n",
    "    if num_channels == 1:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        ax.imshow(image_data[0]) \n",
    "        ax.set_title(f\"Single Channel Image - Label {label}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, num_channels, figsize=(10, 5))\n",
    "        for channel in range(num_channels):\n",
    "            axes[channel].imshow(image_data[channel])\n",
    "            axes[channel].set_title(f\"Channel {channel + 1}\")\n",
    "            axes[channel].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Batch Image - Label {label}\", fontsize=10, y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "visualize_batch(test_data_loader)\n",
    "\n",
    "# Visualize a batch from one of the train DataLoaders\n",
    "#visualize_batch(train_loaders[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653b4bb",
   "metadata": {},
   "source": [
    "## II. Ensemble 2: Retrain de novo model 5 times on different subsets with dropout at test time <a class=\"anchor\" id=\"ensemble2\"></a>\n",
    "\n",
    "Here we retrain the de novo multiclass model on a different subset of each class 5 times via random subset for Case 1. This means we take a different 100000 of each class and retrain. Again, similar to ensembling before, we plot the UMAP and look for screening hits and check for overlaps. We also need to ensure that the classes are balanced in training as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9562aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassClassifier(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        \n",
    "        # VGG-like feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Classifier head for multi-class\n",
    "        self.fc_input_size = 8192 \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.fc_input_size, 4096), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Print the size of x to confirm it's correct\n",
    "        #print(\"Size of x:\", x.size())\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "num_classes = 6\n",
    "model = MultiClassClassifier(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07664290",
   "metadata": {},
   "source": [
    "#### Case 1 (train with classes 0,2)\n",
    "\n",
    "\n",
    "75000 instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad99d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/dss/dsshome1/0F/di93quv/wandb/run-20241006_232503-07qo722n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/07qo722n' target=\"_blank\">seed_42</a></strong> to <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training' target=\"_blank\">https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/07qo722n' target=\"_blank\">https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/07qo722n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of seeds for reproducibility\n",
    "seeds = [42, 101, 202, 303, 404]\n",
    "\n",
    "# Wandb login\n",
    "wandb.login()\n",
    "\n",
    "#load testset once\n",
    "test_data_loader = load_dataset(\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\", batch_size)\n",
    "\n",
    "n_train_instances_per_class = 75000  # Training instances for each class (0 and 2)\n",
    "train_loaders = []\n",
    "target_train_classes = [0, 2]  # We only use classes 0 and 2 for training\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"Currently running ensemble run for seed {seed}...\")\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Redirect print statements to a file (unique for each seed)\n",
    "    sys.stdout = open(f\"ensemble_duplicate_multi_class_output_seed_{seed}.txt\", \"w\")\n",
    "\n",
    "    # Initialize TensorBoard writer (unique directory for each seed)\n",
    "    tensorboard_writer = SummaryWriter(f'runs/ensemble_VGG2_autophagy_multi_class_training_seed_{seed}')\n",
    "\n",
    "    # W&B with unique run name for each seed\n",
    "    run = wandb.init(project=\"ensemble_VGG2_autophagy_multi_class_training\", name=f'seed_{seed}')\n",
    "\n",
    "    # Define the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Create an instance of model\n",
    "    num_classes = 6\n",
    "    model = MultiClassClassifier(num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 5  \n",
    "    batch_size = 256 \n",
    "    log_interval = 50  # Log metrics every 50 batches\n",
    "\n",
    "    epsilon = 1e-8  # Small epsilon value to prevent log(0) in uncertainties\n",
    "    \n",
    "    # 2. Create 5 different training sets with different seeds (for classes 0 and 2)\n",
    "    undersampled_trainset = undersample_dataset(case1_full_trainset_data, target_train_classes, \n",
    "                                                n_instances=n_train_instances_per_class, seed=seed)\n",
    "    \n",
    "    # Create DataLoader for each seed\n",
    "    train_loader = DataLoader(undersampled_trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=14, pin_memory=True)\n",
    "    train_loaders.append(train_loader)\n",
    "\n",
    "    # Print train set class distribution\n",
    "    train_labels = [label for _, label in undersampled_trainset]\n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train set class distribution (seed {seed}): {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    stop_training = False\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        if stop_training:\n",
    "            break  \n",
    "\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = len(train_loader)\n",
    "        batch_counter = 0  # Reset batch counter at the start of each epoch\n",
    "        \n",
    "        #print(len(test_data_loader.dataset))\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.sum().item()\n",
    "            _, predicted = output.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            batch_counter += 1\n",
    "\n",
    "            # Calculate accuracy and average loss for the current batch\n",
    "            accuracy = 100.0 * correct / (batch_counter * batch_size)\n",
    "            average_loss = total_loss / (batch_counter * batch_size)\n",
    "\n",
    "            # Check for the desired accuracy and stop training if reached\n",
    "            if accuracy >= 99.0:\n",
    "                stop_training = True\n",
    "                print(\"Accuracy over 99% reached and thus stopping training...\")\n",
    "                break\n",
    "\n",
    "        # Calculate and log training metrics\n",
    "        all_train_labels = []\n",
    "        all_train_predicted = []\n",
    "\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_precision = precision_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_recall = recall_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_f1 = f1_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_balanced_accuracy = balanced_accuracy_score(all_train_labels, all_train_predicted)\n",
    "\n",
    "        train_accuracy = accuracy_score(all_train_labels, all_train_predicted) * 100.0\n",
    "\n",
    "        print(\"Train Precision: \" + str(train_precision) + \" Recall: \" + str(train_recall) + \" F1 score: \" + str(train_f1))\n",
    "        print(\"Train Balanced Accuracy: {:.2f}%\".format(train_balanced_accuracy))\n",
    "\n",
    "        # Log train metrics for the epoch\n",
    "        wandb.log({\n",
    "            \"Train Epoch\": epoch,\n",
    "            \"Train_Precision\": train_precision,\n",
    "            \"Train_Recall\": train_recall,\n",
    "            \"Train_F1-score\": train_f1,\n",
    "            \"Train_Balanced_Accuracy\": train_balanced_accuracy,\n",
    "            \"Train_Loss\": average_loss,\n",
    "        })\n",
    "\n",
    "        # Log on TensorBoard\n",
    "        tensorboard_writer.add_scalar('Train_Precision', train_precision, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Recall', train_recall, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_F1-score', train_f1, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Balanced_Accuracy', train_balanced_accuracy, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Loss', average_loss, global_step=epoch)\n",
    "\n",
    "        correct = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Test loop with dropout and aggregated confusion matrix\n",
    "        model.eval()\n",
    "\n",
    "        # Enable dropout during testing\n",
    "        model.apply(lambda m: setattr(m, 'training', True))\n",
    "\n",
    "        test_correct = 0\n",
    "        test_average_loss = 0.0\n",
    "        all_test_labels = []\n",
    "        all_test_predicted = []\n",
    "        test_class_uncertainties = [[] for _ in range(num_classes)]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, labels in test_data_loader:\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                _, predicted = output.max(1)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "                all_test_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "                loss = loss_function(output, labels)\n",
    "                test_average_loss += loss.sum().item()\n",
    "\n",
    "                # Calculate class probabilities\n",
    "                probs = torch.nn.functional.softmax(output, dim=1)\n",
    "                    \n",
    "                # Calculate uncertainties (entropy) for each sample\n",
    "                uncertainties = [-torch.sum(p * torch.log(p + epsilon)).item() for p in probs]\n",
    "\n",
    "                # Accumulate uncertainties for each predicted class\n",
    "                predicted_classes = predicted.cpu().numpy()  # Predicted classes from output.max(1)\n",
    "\n",
    "                for idx, pred_class in enumerate(predicted_classes):\n",
    "                    test_class_uncertainties[pred_class].append(uncertainties[idx])\n",
    "\n",
    "\n",
    "        # Filter out predictions and labels for classes seen during training\n",
    "        mask_seen_classes = np.isin(all_test_labels, [0, 2])  # Class 0 and 2 seen at training\n",
    "        filtered_test_labels = np.array(all_test_labels)[mask_seen_classes]\n",
    "        filtered_test_predicted = np.array(all_test_predicted)[mask_seen_classes]\n",
    "\n",
    "        # Calculate accuracy and loss only for the seen classes\n",
    "        test_accuracy = accuracy_score(filtered_test_labels, filtered_test_predicted)\n",
    "        test_average_loss = test_average_loss / len(test_data_loader.dataset)\n",
    "\n",
    "        print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "        print(\"Test Loss: {:.4f}\".format(test_average_loss))\n",
    "\n",
    "        wandb.log({\n",
    "            \"Test_Accuracy\": test_accuracy,\n",
    "            \"Test_Loss\": test_average_loss,\n",
    "        })\n",
    "\n",
    "        tensorboard_writer.add_scalar('Test_Accuracy', test_accuracy, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Test_Loss', test_average_loss, global_step=epoch)\n",
    "\n",
    "        # Aggregate and log confusion matrix\n",
    "        aggregated_confusion = confusion_matrix(all_test_labels, all_test_predicted)\n",
    "\n",
    "        # Confusion matrix\n",
    "        epsilon = 1e-8\n",
    "        df_cm = pd.DataFrame(aggregated_confusion / (np.sum(aggregated_confusion, axis=1)[:, None] + epsilon),\n",
    "                             index=[i for i in range(num_classes)],\n",
    "                             columns=[i for i in range(num_classes)])\n",
    "\n",
    "        # Save confusion matrix to Tensorbboard\n",
    "        figure = sn.heatmap(df_cm, annot=True).get_figure()\n",
    "        tensorboard_writer.add_figure(f'Aggregated Confusion Matrix - Epoch {epoch}', figure, global_step=epoch)\n",
    "\n",
    "        # Set the model back to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Plot histogram of uncertainties\n",
    "        class1_uncertainties = test_class_uncertainties[1]\n",
    "        plt.hist(class1_uncertainties, bins=50, alpha=0.5, color='blue', label='Class 1 Uncertainties')\n",
    "        plt.xlabel('Uncertainty')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Uncertainty Distribution for Class 1')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'ensemble_uncertainty_histogram_class1_epoch{epoch}_seed_{seed}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Save model (unique for each seed)\n",
    "    try:\n",
    "        print(f\"Saving final model for seed {seed} now...\")\n",
    "        torch.save(model.state_dict(), f'ensemble_multi_class_VGG2_case1_seed_{seed}.pth')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model for seed {seed}: {str(e)}\")\n",
    "\n",
    "    # Close the W&B run\n",
    "    wandb.finish()\n",
    "    \n",
    "    # Close file and reset stdout\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = sys.__stdout__  # Reset to default stdout\n",
    "\n",
    "    # Close the TensorBoard writer\n",
    "    tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trainset, seed) in enumerate(zip(train_loaders, seeds)):\n",
    "    save_dataset(trainset.dataset, seed, f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/undersampled_trainset_seed_{seed}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84440b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48000320\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:02 undersampled_trainset_seed_101.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_202.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_303.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_404.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401480 Oct  7 01:02 undersampled_trainset_seed_42.pt\n"
     ]
    }
   ],
   "source": [
    "# Load undersampled training sets\n",
    "!ls -l /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39061fc7",
   "metadata": {},
   "source": [
    "Here we create a new training dataset for every seed and we can modify the loop to generate a new dataset for each seed before retraining on that dataset. This way, the model is retrained on different subsets of the data for each seed, achieving the desired variation in the training data while keeping the test data constant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
