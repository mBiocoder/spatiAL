{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a089c184",
   "metadata": {},
   "source": [
    "# Retrain the de novo model with a seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a060f",
   "metadata": {},
   "source": [
    "<b> What is our goal? <b>\n",
    "\n",
    "The main goal is to develop a model that has meaningful uncertainty, meaning the uncertainty is low for known and biologically uninteresting classes, but high for unknown and ideally biologically interesting classes. Our hope would be that this new model learns something the original classifier (autophagy_2_1 from SPACRSpy) did not, thereby identifying something new.\n",
    "The way to test this for the multi-class classifier is by leaving out different biological conditions during training and then checking uncertainty on them as well as by evaluate the new model with screening data, plotting its 8th layer in UMAP and investigating the classifcation scores between the old and new models.\n",
    "\n",
    "\n",
    "<b> What data do we have now? <b>\n",
    "\n",
    "1. Stimulated 14h (or 16h) -> labelled as 0\n",
    "2. Unstimulated -> labelled as 1\n",
    "3. ATG5 KO (stimulated but that doesn’t matter, this KO supersedes the stim status [probably looks like unstimulated data]) -> labelled as 2\n",
    "4. Stimulated timecourse data -> labelled as 3\n",
    "5. EI24 KO timecourse data (more similar to unstim) -> labelled as 4\n",
    "6. Screening data (similar to stim) -> labelled as 5\n",
    "\n",
    "\n",
    "<b> What are we doing in this section? <b>\n",
    "\n",
    "We randomly sample 75,000 instances per class (e.g., 0 and 2 in the first case), train the de novo classifier on this subset and save the resulting model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7818f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torch-intermediate-layer-getter\n",
      "  Downloading torch_intermediate_layer_getter-0.1.post1.tar.gz (3.0 kB)\n",
      "Building wheels for collected packages: torch-intermediate-layer-getter\n",
      "  Building wheel for torch-intermediate-layer-getter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-intermediate-layer-getter: filename=torch_intermediate_layer_getter-0.1.post1-py3-none-any.whl size=3724 sha256=d23cee0c5fea6142e1a3fba488e85c692bc4855c516010a87ebb65d7051bb27a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7962veem/wheels/6a/11/c0/30d81aa26172d10d68ffaf352b0762eb9fe0a5f5dcf3de63e0\n",
      "Successfully built torch-intermediate-layer-getter\n",
      "Installing collected packages: torch-intermediate-layer-getter\n",
      "Successfully installed torch-intermediate-layer-getter-0.1.post1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting leidenalg\n",
      "  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting igraph<0.12,>=0.10.0\n",
      "  Downloading igraph-0.11.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 26.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting texttable>=1.6.2\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, igraph, leidenalg\n",
      "Successfully installed igraph-0.11.8 leidenalg-0.10.2 texttable-1.7.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scanpy==1.9.6\n",
      "  Downloading scanpy-1.9.6-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=3 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.9.0)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.1)\n",
      "Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: session-info in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.0.0)\n",
      "Requirement already satisfied: umap-learn>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.5.7)\n",
      "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.10.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (4.65.0)\n",
      "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.14.4)\n",
      "Requirement already satisfied: anndata>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.11.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (23.1)\n",
      "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.5.6)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.2.0)\n",
      "Requirement already satisfied: pandas!=2.1.2,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (1.5.2)\n",
      "Requirement already satisfied: seaborn!=0.13.0 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (0.13.2)\n",
      "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from scanpy==1.9.6) (3.7.1)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scanpy==1.9.6) (1.9.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scanpy==1.9.6) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (4.39.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->scanpy==1.9.6) (1.4.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.41.0->scanpy==1.9.6) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.2,>=1.1.1->scanpy==1.9.6) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->scanpy==1.9.6) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->scanpy==1.9.6) (3.1.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.3.10->scanpy==1.9.6) (0.5.13)\n",
      "Requirement already satisfied: stdlib-list in /usr/local/lib/python3.10/dist-packages (from session-info->scanpy==1.9.6) (0.11.0)\n",
      "Installing collected packages: scanpy\n",
      "  Attempting uninstall: scanpy\n",
      "    Found existing installation: scanpy 1.10.3\n",
      "\u001b[33m    WARNING: Value for bin_prefix does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "    distutils: /usr/bin\n",
      "    sysconfig: /usr/local/bin\u001b[0m\n",
      "\u001b[33m    WARNING: Additional context:\n",
      "    user = False\n",
      "    home = None\n",
      "    root = None\n",
      "    prefix = None\u001b[0m\n",
      "    Uninstalling scanpy-1.10.3:\n",
      "      Successfully uninstalled scanpy-1.10.3\n",
      "Successfully installed scanpy-1.9.6\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: anndata in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
      "Requirement already satisfied: pandas!=2.1.0rc0,!=2.1.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.5.2)\n",
      "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata) (8.4.0)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.9.1)\n",
      "Requirement already satisfied: h5py>=3.6 in /usr/local/lib/python3.10/dist-packages (from anndata) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from anndata) (23.1)\n",
      "Requirement already satisfied: scipy>1.8 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from anndata) (1.23.5)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata) (1.1.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.56.4+1.g5f1bc7084)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting watermark\n",
      "  Downloading watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (8.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (65.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.15.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.38)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.15.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.0->watermark) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.0->watermark) (0.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.16.0)\n",
      "Installing collected packages: watermark\n",
      "Successfully installed watermark-2.5.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-intermediate-layer-getter\n",
    "!pip install umap-learn\n",
    "!pip install leidenalg\n",
    "!pip install scanpy==1.9.6\n",
    "!pip install anndata umap-learn\n",
    "!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9926e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nexusformat\n",
      "  Downloading nexusformat-1.0.6-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hdf5plugin\n",
      "  Downloading hdf5plugin-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.6 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nexusformat) (1.10.1)\n",
      "Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.10/dist-packages (from nexusformat) (3.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nexusformat) (1.23.5)\n",
      "Installing collected packages: hdf5plugin, nexusformat\n",
      "Successfully installed hdf5plugin-5.0.0 nexusformat-1.0.6\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nexusformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce72312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_csv from `anndata` is deprecated. Import anndata.io.read_csv instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_excel from `anndata` is deprecated. Import anndata.io.read_excel instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_mtx from `anndata` is deprecated. Import anndata.io.read_mtx instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_loom from `anndata` is deprecated. Import anndata.io.read_loom instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_hdf from `anndata` is deprecated. Import anndata.io.read_hdf instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/anndata/utils.py:429: FutureWarning: Importing read_umi_tools from `anndata` is deprecated. Import anndata.io.read_umi_tools instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    }
   ],
   "source": [
    "#%load_ext watermark\n",
    " \n",
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "import sys\n",
    "import seaborn as sn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n",
    "import umap\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "import h5py\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sparcscore.ml.datasets import HDF5SingleCellDataset\n",
    "# from sparcscore.pipeline.project import TimecourseProject, Project\n",
    "# from sparcscore.pipeline.workflows import MultithreadedWGATimecourseSegmentation, WGATimecourseSegmentation, MultithreadedCytosolCellposeTimecourseSegmentation, ShardedWGASegmentation, ShardedDAPISegmentationCellpose, WGASegmentation, DAPISegmentationCellpose\n",
    "from sparcscore.pipeline.extraction import HDF5CellExtraction, TimecourseHDF5CellExtraction\n",
    "from sparcscore.pipeline.classification import MLClusterClassifier\n",
    "from sparcscore.ml.pretrained_models import autophagy_classifier2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7606826",
   "metadata": {},
   "source": [
    "## I. Load in full data and big and small test sets <a class=\"anchor\" id=\"test-set\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f7fabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3426407\n",
      "0: 407464\n",
      "1: 209030\n",
      "2: 400000\n",
      "3: 9346\n",
      "4: 7476\n",
      "5: 2393091\n"
     ]
    }
   ],
   "source": [
    "full_hdf5_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_A002/single_cells.h5', \n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_B004/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_D001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_F003/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_H002/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_K001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_0d.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_4h.h5'],\n",
    "    dir_labels=[4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67cd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import h5py\n",
    "   \n",
    "class HDF5SingleCellDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class for handling SPARCSpy single cell datasets stored in HDF5 files.\n",
    "\n",
    "    This class provides a convenient interface for SPARCSpy formated hdf5 files containing single cell datasets. It supports loading data\n",
    "    from multiple hdf5 files within specified directories, applying transformations on the data, and returning\n",
    "    the required information, such as label or id, along with the single cell data.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    root_dir : str\n",
    "        Root directory where the hdf5 files are located.\n",
    "    dir_labels : list of int\n",
    "        List of labels corresponding to the directories in dir_list.\n",
    "    dir_list : list of str\n",
    "        List of path(s) where the hdf5 files are stored. Supports specifying a path to a specific hdf5 file or directory\n",
    "        containing hdf5 files.\n",
    "    transform : callable, optional\n",
    "        A optional user-defined function to apply transformations to the data. Default is None.\n",
    "    max_level : int, optional\n",
    "        Maximum levels of directory to search for hdf5 files. Default is 5.\n",
    "    return_id : bool, optional\n",
    "        Whether to return the index of the cell with the data. Default is False.\n",
    "    return_fake_id : bool, optional\n",
    "        Whether to return a fake index (0) with the data. Default is False.\n",
    "    select_channel : int, optional\n",
    "        Specify a specific channel to select from the data. Default is None, which returns all channels.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    add_hdf_to_index(current_label, path)\n",
    "        Adds single cell data from the hdf5 file located at ‘path’ with the specified ‘current_label’ to the index.\n",
    "    scan_directory(path, current_label, levels_left)\n",
    "        Scans directories for hdf5 files and adds their data to the index with the specified ‘current_label’.\n",
    "    stats()\n",
    "        Prints dataset statistics including total count and count per label.\n",
    "    len()\n",
    "        Returns the total number of single cells in the dataset.\n",
    "    getitem(idx)\n",
    "        Returns the data, label, and optional id/fake_id of the single cell specified by the index ‘idx’.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> hdf5_data = HDF5SingleCellDataset(dir_list=[‘data1.hdf5’, ‘data2.hdf5’],\n",
    "    dir_labels=[0, 1],\n",
    "    root_dir=‘/path/to/data’,\n",
    "    transform=None,\n",
    "    return_id=True)\n",
    "    >>> len(hdf5_data)\n",
    "    2000\n",
    "    >>> sample = hdf5_data[0]\n",
    "    >>> sample[0].shape\n",
    "    torch.Size([1, 128, 128])\n",
    "    >>> sample[1]\n",
    "    tensor(0)\n",
    "    >>> sample[2]\n",
    "    tensor(0)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    HDF_FILETYPES = [\"hdf\", \"hf\", \"h5\", \"hdf5\"]\n",
    "    def __init__(self, dir_list, \n",
    "                 dir_labels, \n",
    "                 root_dir, \n",
    "                 max_level=5, \n",
    "                 transform=None, \n",
    "                 return_id=False, \n",
    "                 return_fake_id=False,\n",
    "                 select_channel=None):\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.dir_labels = dir_labels\n",
    "        self.dir_list = dir_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.handle_list = []\n",
    "        self.data_locator = []\n",
    "        \n",
    "        self.select_channel = select_channel\n",
    "        \n",
    "        # scan all directoreis\n",
    "        for i, directory in enumerate(dir_list):\n",
    "            path = os.path.join(self.root_dir, directory)  \n",
    "            current_label = self.dir_labels[i]\n",
    "\n",
    "            #check if \"directory\" is a path to specific hdf5\n",
    "            filetype = directory.split(\".\")[-1]\n",
    "            filename = directory.split(\".\")[0]\n",
    "                \n",
    "            if filetype in self.HDF_FILETYPES:\n",
    "                self.add_hdf_to_index(current_label, directory)\n",
    "\n",
    "            else:\n",
    "                # recursively scan for files\n",
    "                self.scan_directory(path, current_label, max_level)\n",
    "        \n",
    "        # print dataset stats at the end\n",
    "        \n",
    "        self.return_id = return_id\n",
    "        self.return_fake_id = return_fake_id\n",
    "        self.stats()\n",
    " \n",
    "        \n",
    "    def add_hdf_to_index(self, current_label, path):       \n",
    "        try:\n",
    "            input_hdf = h5py.File(path, 'r')\n",
    "            index_handle = input_hdf.get('single_cell_index')\n",
    "\n",
    "            handle_id = len(self.handle_list)\n",
    "            self.handle_list.append(input_hdf.get('single_cell_data'))\n",
    "\n",
    "            for row in index_handle:\n",
    "                self.data_locator.append([current_label, handle_id]+list(row))      \n",
    "        except:\n",
    "            return\n",
    "        \n",
    "    def scan_directory(self, path, current_label, levels_left):\n",
    "        \n",
    "        # iterates over all files and folders in a directory\n",
    "        # hdf5 files are added to the index\n",
    "        # subfolders are recursively scanned\n",
    "        \n",
    "        if levels_left > 0:\n",
    "            \n",
    "            # get files and directories at current level\n",
    "            input_list = os.listdir(path)\n",
    "            current_level_directories = [os.path.join(path, name) for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
    "\n",
    "            current_level_files = [ name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]\n",
    "                        \n",
    "            for i, file in enumerate(current_level_files):\n",
    "                filetype = file.split(\".\")[-1]\n",
    "                filename = file.split(\".\")[0]\n",
    "                \n",
    "                if filetype in self.HDF_FILETYPES:\n",
    "                    \n",
    "                    self.add_hdf_to_index(current_label, os.path.join(path, file))\n",
    "                    \n",
    "            # recursively scan subdirectories        \n",
    "            for subdirectory in current_level_directories:\n",
    "                self.scan_directory(subdirectory, current_label, levels_left-1)\n",
    "            \n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def stats(self):\n",
    "    \n",
    "        labels = [el[0] for el in self.data_locator]\n",
    "        \n",
    "        print(\"Total: {}\".format(len(labels)))\n",
    "        \n",
    "        for l in set(labels):\n",
    "            print(\"{}: {}\".format(l,labels.count(l)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_locator)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # get the label, filename and directory for the current dataset\n",
    "        data_info = self.data_locator[idx]\n",
    "        \n",
    "        if self.select_channel is not None:\n",
    "            cell_tensor = self.handle_list[data_info[1]][data_info[2], self.select_channel]\n",
    "            t = torch.from_numpy(cell_tensor)\n",
    "            t = torch.unsqueeze(t,0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            cell_tensor = self.handle_list[data_info[1]][data_info[2]]\n",
    "            t = torch.from_numpy(cell_tensor)\n",
    "            \n",
    "        t = t.float()     \n",
    "        \n",
    "        if self.transform:\n",
    "            t = self.transform(t)\n",
    "        \"\"\"  \n",
    "        if not list(t.shape) == list(torch.Size([1,128,128])):\n",
    "            t = torch.zeros((1,128,128))\n",
    "        \"\"\"      \n",
    "        if self.return_id and self.return_fake_id:\n",
    "            raise ValueError(\"either return_id or return_fake_id should be set\")\n",
    "            \n",
    "        if self.return_id:\n",
    "            \n",
    "            ids = int(data_info[3])\n",
    "            sample = (t, torch.tensor(data_info[0]), torch.tensor(ids))\n",
    "        elif self.return_fake_id:\n",
    "            \n",
    "            sample = (t, torch.tensor(data_info[0]), torch.tensor(0))\n",
    "        else:\n",
    "            sample = (t, torch.tensor(data_info[0]))\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0c2945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1068071\n",
      "0: 100000\n",
      "1: 100000\n",
      "2: 100000\n",
      "3: 2459\n",
      "4: 2608\n",
      "5: 763004\n"
     ]
    }
   ],
   "source": [
    "full_testset_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_A002/single_cells.h5', \n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_B004/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_01_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_4h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_4h.h5',\n",
    "             ],\n",
    "    dir_labels=[4, 4, 5, 5, 2, 0, 1, 3, 3], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2201b",
   "metadata": {},
   "source": [
    "From full_hdf5_data only the first (few) files are used for building the independant, full and unbalanced testset. For the full unbalanced trainset we take all other files except the first one which was used for creating the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45a2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 2358336\n",
      "0: 307464\n",
      "1: 109030\n",
      "2: 300000\n",
      "3: 6887\n",
      "4: 4868\n",
      "5: 1630087\n"
     ]
    }
   ],
   "source": [
    "case1_full_trainset_data = HDF5SingleCellDataset(\n",
    "    dir_list=['/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_EI24KO_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_EI24KO_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_D001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_F003/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_H002/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231004_autophagy_screen_6slides/2.3_K001/single_cells.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_Cr203_C6_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_Cr203_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.2_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_2.3_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_stim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_14h.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/T_02_unstim_wt_filtered.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0316_EI24_fixed_tc/231018_0316_EI24_fixed_tc_WT_2_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_0d.h5',\n",
    "              '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_1_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0317_EI24_fixed_tc/231018_0317_EI24_fixed_tc_WT_2_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_1_4h.h5',\n",
    "             '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/231018_EI24_timecourse_phenix/231018_0318_EI24_fixed_tc/231018_0318_EI24_fixed_tc_WT_2_4h.h5'\n",
    "             ],\n",
    "    dir_labels=[4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3], \n",
    "    root_dir='/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93kux/230714_autophagy_training_data_sample/',\n",
    "    select_channel=4,  # Select the 5th channel (channel index 4)\n",
    "    return_id=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3392b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def undersample_dataset(dataset, target_classes, n_instances=None, seed=None):\n",
    "    \"\"\"\n",
    "    Undersamples the dataset so target_classes have equal number of instances.\n",
    "    If n_instances is set, each class will have n_instances samples.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: PyTorch Dataset object containing the features (e.g., HDF5SingleCellDataset)\n",
    "    - target_classes: the list of classes to undersample (e.g., [0, 2] for training)\n",
    "    - n_instances: number of samples per class (None means use minimum of class sizes)\n",
    "    - seed: random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - undersampled_dataset: the undersampled dataset (list of samples)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    undersampled_data = []\n",
    "    \n",
    "    for cls in target_classes:\n",
    "        class_indices = [i for i, (_, label) in enumerate(dataset) if label == cls]\n",
    "        if n_instances is None:\n",
    "            n_instances = len(class_indices)\n",
    "        \n",
    "        # Randomly sample n_instances for each class\n",
    "        sampled_indices = np.random.choice(class_indices, n_instances, replace=False)\n",
    "        undersampled_data.extend([dataset[i] for i in sampled_indices])\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    undersampled_data = shuffle(undersampled_data, random_state=seed)\n",
    "    return undersampled_data\n",
    "\n",
    "# Function to create balanced testset for classes 0-5\n",
    "def create_balanced_testset(dataset, target_classes, n_instances_per_class):\n",
    "    \"\"\"\n",
    "    Create a balanced testset with n_instances_per_class for each class in target_classes.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: PyTorch Dataset object (e.g., HDF5SingleCellDataset)\n",
    "    - target_classes: list of classes (e.g., [0, 1, 2, 3, 4, 5])\n",
    "    - n_instances_per_class: number of instances to sample per class\n",
    "    \n",
    "    Returns:\n",
    "    - balanced_testset: list of samples with balanced instances per class\n",
    "    \"\"\"\n",
    "    balanced_data = []\n",
    "    \n",
    "    for cls in target_classes:\n",
    "        print(cls)\n",
    "        class_indices = [i for i, (_, label) in enumerate(dataset) if label == cls]\n",
    "        # Randomly sample n_instances_per_class for each class\n",
    "        sampled_indices = np.random.choice(class_indices, n_instances_per_class, replace=False)\n",
    "        balanced_data.extend([dataset[i] for i in sampled_indices])\n",
    "    \n",
    "    # Shuffle balanced testset\n",
    "    balanced_data = shuffle(balanced_data, random_state=42)  # Fixed seed for test set\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e710a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save dataset as torch tensor\n",
    "def save_dataset(dataset, labels, save_path):\n",
    "    # Convert the dataset to a single tensor (stack the data)\n",
    "    images_tensor = torch.stack([dataset[i][0] for i in range(len(dataset))])\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    # Save the tensors\n",
    "    torch.save((images_tensor, labels_tensor), save_path)\n",
    "    print(f\"Dataset saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584fa2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load saved dataset and recreate DataLoader\n",
    "def load_dataset(save_path, batch_size):\n",
    "    # Load the saved tensor data\n",
    "    images_tensor, labels_tensor = torch.load(save_path)\n",
    "    \n",
    "    # Create a TensorDataset from the loaded tensors\n",
    "    dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f\"Loaded dataset from {save_path}\")\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab75dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1]   # Different seeds for ensembling\n",
    "batch_size = 256                    # Batch size for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa95c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 1. Create balanced testset for classes 0-5 (fixed across all training processes)\n",
    "n_test_instances_per_class = 2000    # Test instances for each class (0-5)\n",
    "\n",
    "target_test_classes = [0, 1, 2, 3, 4, 5]\n",
    "balanced_testset = create_balanced_testset(full_testset_data, target_test_classes, n_test_instances_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5436a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 14 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set class distribution (balanced): {0: 2000, 1: 2000, 2: 2000, 3: 2000, 4: 2000, 5: 2000}\n"
     ]
    }
   ],
   "source": [
    "# Create test DataLoader (shared for all training processes)\n",
    "test_data_loader = DataLoader(balanced_testset, batch_size=batch_size, shuffle=True, num_workers=14, pin_memory=True)\n",
    "\n",
    "# Print test set class distribution\n",
    "test_labels = [label for _, label in balanced_testset]\n",
    "unique, counts = np.unique(test_labels, return_counts=True)\n",
    "print(f\"Test set class distribution (balanced): {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae6a1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved at /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced testset and undersampled training sets\n",
    "balanced_test_labels = [label for _, label in balanced_testset]  # Extracting labels\n",
    "save_dataset(balanced_testset, balanced_test_labels, \"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc2e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create 5 different training sets with different seeds (for classes 0 and 2)\n",
    "n_train_instances_per_class = 75000 # Training instances for each class (0 and 2)\n",
    "train_loaders = []\n",
    "target_train_classes = [0, 2]  # We only use classes 0 and 2 for training\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"seed \" + str(seed))\n",
    "    undersampled_trainset = undersample_dataset(case1_full_trainset_data, target_train_classes, \n",
    "                                                n_instances=n_train_instances_per_class, seed=seed)\n",
    "    \n",
    "    # Create DataLoader for each seed\n",
    "    train_loader = DataLoader(undersampled_trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=14, pin_memory=True)\n",
    "    train_loaders.append(train_loader)\n",
    "\n",
    "    # Print train set class distribution\n",
    "    train_labels = [label for _, label in undersampled_trainset]\n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train set class distribution (seed {seed}): {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5250df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trainset, train_labels) in enumerate(zip(train_loaders, seeds)):\n",
    "    save_dataset(trainset.dataset, train_labels, f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/undersampled_trainset_seed_{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1e3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the balanced testset\n",
    "test_data_loader = load_dataset(\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585bd47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 279360\n",
      "-rw-rw---- 1 di93quv pn36po 65554048 Sep 17 18:26  trainset_0_seed_42.h5\n",
      "-rw-rw---- 1 di93quv pn36po 65554048 Sep 17 18:27  trainset_2_seed_42.h5\n",
      "-rw-rw---- 1 di93quv pn36po 82019584 Sep 29 22:31 'trainset_[0, 2]_seed_42.h5'\n",
      "-rw-rw---- 1 di93quv pn36po    23113 Sep 29 22:31  trainset_indices_42.pkl\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_0.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_1.pt\n",
      "-rw-rw---- 1 di93quv pn36po 13108633 Oct  6 23:03  undersampled_trainset_seed_101.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_2.pt\n",
      "-rw-rw---- 1 di93quv pn36po 13108633 Oct  6 23:03  undersampled_trainset_seed_202.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_3.pt\n",
      "-rw-rw---- 1 di93quv pn36po 13108633 Oct  6 23:03  undersampled_trainset_seed_303.pt\n",
      "-rw-rw---- 1 di93quv pn36po  1312079 Oct  5 17:51  undersampled_trainset_seed_4.pt\n",
      "-rw-rw---- 1 di93quv pn36po 13108633 Oct  6 23:03  undersampled_trainset_seed_404.pt\n",
      "-rw-rw---- 1 di93quv pn36po 13108628 Oct  6 23:03  undersampled_trainset_seed_42.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -l /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1_small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load undersampled training sets\n",
    "train_loaders = []\n",
    "for i in range(len(seeds)):\n",
    "    train_loader = load_dataset(f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1_small/undersampled_trainset_seed_{i}.pt\", batch_size)\n",
    "    train_loaders.append(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d35e965a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_batch(data_loader):\n",
    "    images, labels = next(iter(data_loader)) \n",
    "\n",
    "    # Visualize the first image in the batch\n",
    "    image_data = images[0].numpy() \n",
    "    label = labels[0].item()  # Convert label tensor to Python int\n",
    "    \n",
    "    num_channels = image_data.shape[0]  # number of channels\n",
    "    \n",
    "    if num_channels == 1:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        ax.imshow(image_data[0]) \n",
    "        ax.set_title(f\"Single Channel Image - Label {label}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, num_channels, figsize=(10, 5))\n",
    "        for channel in range(num_channels):\n",
    "            axes[channel].imshow(image_data[channel])\n",
    "            axes[channel].set_title(f\"Channel {channel + 1}\")\n",
    "            axes[channel].axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Batch Image - Label {label}\", fontsize=10, y=1.05)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a batch from the test DataLoader\n",
    "visualize_batch(test_data_loader)\n",
    "\n",
    "# Visualize a batch from one of the train DataLoaders\n",
    "#visualize_batch(train_loaders[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f0609a",
   "metadata": {},
   "source": [
    "## II. Ensemble 2: Retrain de novo model 5 times on different subsets with dropout at test time <a class=\"anchor\" id=\"ensemble2\"></a>\n",
    "\n",
    "Here we retrain the de novo multiclass model on a different subset of each class 5 times via random subset for Case 1. This means we take a different 100000 of each class and retrain. Again, similar to ensembling before, we plot the UMAP and look for screening hits and check for overlaps. We also need to ensure that the classes are balanced in training as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "468815e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassClassifier(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=1024, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MultiClassClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassClassifier, self).__init__()\n",
    "        \n",
    "        # VGG-like feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Classifier head for multi-class\n",
    "        self.fc_input_size = 8192 \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.fc_input_size, 4096), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Print the size of x to confirm it's correct\n",
    "        #print(\"Size of x:\", x.size())\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "num_classes = 6\n",
    "model = MultiClassClassifier(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffca40f",
   "metadata": {},
   "source": [
    "#### Case 1 (train with classes 0,2)\n",
    "\n",
    "\n",
    "75000 instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "278473f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarunku\u001b[0m (\u001b[33mcrisprscreen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\n",
      "Currently running ensemble run for seed 1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/dss/dsshome1/0F/di93quv/wandb/run-20241110_182402-ttylzzrd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/ttylzzrd' target=\"_blank\">seed_1</a></strong> to <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training' target=\"_blank\">https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/ttylzzrd' target=\"_blank\">https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/ttylzzrd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 14 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 14 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test_Accuracy</td><td>▁█</td></tr><tr><td>Test_Loss</td><td>█▁</td></tr><tr><td>Train Epoch</td><td>▁█</td></tr><tr><td>Train_Balanced_Accuracy</td><td>█▁</td></tr><tr><td>Train_F1-score</td><td>█▁</td></tr><tr><td>Train_Loss</td><td>█▁</td></tr><tr><td>Train_Precision</td><td>█▁</td></tr><tr><td>Train_Recall</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test_Accuracy</td><td>0.78775</td></tr><tr><td>Test_Loss</td><td>0.08817</td></tr><tr><td>Train Epoch</td><td>2</td></tr><tr><td>Train_Balanced_Accuracy</td><td>0.99196</td></tr><tr><td>Train_F1-score</td><td>0.99196</td></tr><tr><td>Train_Loss</td><td>9e-05</td></tr><tr><td>Train_Precision</td><td>0.99201</td></tr><tr><td>Train_Recall</td><td>0.99196</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">seed_1</strong> at: <a href='https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/ttylzzrd' target=\"_blank\">https://wandb.ai/crisprscreen/ensemble_VGG2_autophagy_multi_class_training/runs/ttylzzrd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241110_182402-ttylzzrd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved at /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/undersampled_trainset_seed_1.pt\n",
      "total 67168640\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:45 undersampled_trainset_seed_0.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:51 undersampled_trainset_seed_1.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:02 undersampled_trainset_seed_101.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_202.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_303.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_404.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401480 Oct  7 01:02 undersampled_trainset_seed_42.pt\n",
      "total 67200448\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:45 undersampled_trainset_seed_0.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:51 undersampled_trainset_seed_1.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:02 undersampled_trainset_seed_101.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_202.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_303.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_404.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401480 Oct  7 01:02 undersampled_trainset_seed_42.pt\n",
      "total 67200448\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:45 undersampled_trainset_seed_0.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401475 Nov 10 18:51 undersampled_trainset_seed_1.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:02 undersampled_trainset_seed_101.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_202.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_303.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401485 Oct  7 01:03 undersampled_trainset_seed_404.pt\n",
      "-rw-rw---- 1 di93quv pn36po 9830401480 Oct  7 01:02 undersampled_trainset_seed_42.pt\n"
     ]
    }
   ],
   "source": [
    "# List of seeds for reproducibility\n",
    "seeds = [1]\n",
    "\n",
    "# Wandb login\n",
    "wandb.login()\n",
    "\n",
    "#load testset once\n",
    "test_data_loader = load_dataset(\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/balanced_testset_all_classes/balanced_testset.pt\", batch_size)\n",
    "\n",
    "n_train_instances_per_class = 75000  # Training instances for each class (0 and 2)\n",
    "train_loaders = []\n",
    "target_train_classes = [0, 2]  # We only use classes 0 and 2 for training\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"Currently running ensemble run for seed {seed}...\")\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Redirect print statements to a file (unique for each seed)\n",
    "    sys.stdout = open(f\"ensemble_duplicate_multi_class_output_seed_{seed}.txt\", \"w\")\n",
    "\n",
    "    # Initialize TensorBoard writer (unique directory for each seed)\n",
    "    tensorboard_writer = SummaryWriter(f'runs/ensemble_VGG2_autophagy_multi_class_training_seed_{seed}')\n",
    "\n",
    "    # W&B with unique run name for each seed\n",
    "    run = wandb.init(project=\"ensemble_VGG2_autophagy_multi_class_training\", name=f'seed_{seed}')\n",
    "\n",
    "    # Define the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Create an instance of model\n",
    "    num_classes = 6\n",
    "    model = MultiClassClassifier(num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 5  \n",
    "    batch_size = 256 \n",
    "    log_interval = 50  # Log metrics every 50 batches\n",
    "\n",
    "    epsilon = 1e-8  # Small epsilon value to prevent log(0) in uncertainties\n",
    "    \n",
    "    # 2. Create 5 different training sets with different seeds (for classes 0 and 2)\n",
    "    undersampled_trainset = undersample_dataset(case1_full_trainset_data, target_train_classes, \n",
    "                                                n_instances=n_train_instances_per_class, seed=seed)\n",
    "    \n",
    "    # Create DataLoader for each seed\n",
    "    train_loader = DataLoader(undersampled_trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=14, pin_memory=True)\n",
    "    train_loaders.append(train_loader)\n",
    "\n",
    "    # Print train set class distribution\n",
    "    train_labels = [label for _, label in undersampled_trainset]\n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    print(f\"Train set class distribution (seed {seed}): {dict(zip(unique, counts))}\")\n",
    "    \n",
    "    stop_training = False\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        if stop_training:\n",
    "            break  \n",
    "\n",
    "        print(\"Epoch: \", epoch)\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total_samples = len(train_loader)\n",
    "        batch_counter = 0  # Reset batch counter at the start of each epoch\n",
    "        \n",
    "        #print(len(test_data_loader.dataset))\n",
    "\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.sum().item()\n",
    "            _, predicted = output.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            batch_counter += 1\n",
    "\n",
    "            # Calculate accuracy and average loss for the current batch\n",
    "            accuracy = 100.0 * correct / (batch_counter * batch_size)\n",
    "            average_loss = total_loss / (batch_counter * batch_size)\n",
    "\n",
    "            # Check for the desired accuracy and stop training if reached\n",
    "            if accuracy >= 99.0:\n",
    "                stop_training = True\n",
    "                print(\"Accuracy over 99% reached and thus stopping training...\")\n",
    "                break\n",
    "\n",
    "        # Calculate and log training metrics\n",
    "        all_train_labels = []\n",
    "        all_train_predicted = []\n",
    "\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "        train_precision = precision_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_recall = recall_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_f1 = f1_score(all_train_labels, all_train_predicted, average='macro')\n",
    "        train_balanced_accuracy = balanced_accuracy_score(all_train_labels, all_train_predicted)\n",
    "\n",
    "        train_accuracy = accuracy_score(all_train_labels, all_train_predicted) * 100.0\n",
    "\n",
    "        print(\"Train Precision: \" + str(train_precision) + \" Recall: \" + str(train_recall) + \" F1 score: \" + str(train_f1))\n",
    "        print(\"Train Balanced Accuracy: {:.2f}%\".format(train_balanced_accuracy))\n",
    "\n",
    "        # Log train metrics for the epoch\n",
    "        wandb.log({\n",
    "            \"Train Epoch\": epoch,\n",
    "            \"Train_Precision\": train_precision,\n",
    "            \"Train_Recall\": train_recall,\n",
    "            \"Train_F1-score\": train_f1,\n",
    "            \"Train_Balanced_Accuracy\": train_balanced_accuracy,\n",
    "            \"Train_Loss\": average_loss,\n",
    "        })\n",
    "\n",
    "        # Log on TensorBoard\n",
    "        tensorboard_writer.add_scalar('Train_Precision', train_precision, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Recall', train_recall, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_F1-score', train_f1, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Balanced_Accuracy', train_balanced_accuracy, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Train_Loss', average_loss, global_step=epoch)\n",
    "\n",
    "        correct = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # Test loop with dropout and aggregated confusion matrix\n",
    "        model.eval()\n",
    "\n",
    "        # Enable dropout during testing\n",
    "        model.apply(lambda m: setattr(m, 'training', True))\n",
    "\n",
    "        test_correct = 0\n",
    "        test_average_loss = 0.0\n",
    "        all_test_labels = []\n",
    "        all_test_predicted = []\n",
    "        test_class_uncertainties = [[] for _ in range(num_classes)]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, labels in test_data_loader:\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                _, predicted = output.max(1)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "                all_test_labels.extend(labels.cpu().numpy())\n",
    "                all_test_predicted.extend(predicted.cpu().numpy())\n",
    "\n",
    "                loss = loss_function(output, labels)\n",
    "                test_average_loss += loss.sum().item()\n",
    "\n",
    "                # Calculate class probabilities\n",
    "                probs = torch.nn.functional.softmax(output, dim=1)\n",
    "                    \n",
    "                # Calculate uncertainties (entropy) for each sample\n",
    "                uncertainties = [-torch.sum(p * torch.log(p + epsilon)).item() for p in probs]\n",
    "\n",
    "                # Accumulate uncertainties for each predicted class\n",
    "                predicted_classes = predicted.cpu().numpy()  # Predicted classes from output.max(1)\n",
    "\n",
    "                for idx, pred_class in enumerate(predicted_classes):\n",
    "                    test_class_uncertainties[pred_class].append(uncertainties[idx])\n",
    "\n",
    "\n",
    "        # Filter out predictions and labels for classes seen during training\n",
    "        mask_seen_classes = np.isin(all_test_labels, [0, 2])  # Class 0 and 2 seen at training\n",
    "        filtered_test_labels = np.array(all_test_labels)[mask_seen_classes]\n",
    "        filtered_test_predicted = np.array(all_test_predicted)[mask_seen_classes]\n",
    "\n",
    "        # Calculate accuracy and loss only for the seen classes\n",
    "        test_accuracy = accuracy_score(filtered_test_labels, filtered_test_predicted)\n",
    "        test_average_loss = test_average_loss / len(test_data_loader.dataset)\n",
    "\n",
    "        print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "        print(\"Test Loss: {:.4f}\".format(test_average_loss))\n",
    "\n",
    "        wandb.log({\n",
    "            \"Test_Accuracy\": test_accuracy,\n",
    "            \"Test_Loss\": test_average_loss,\n",
    "        })\n",
    "\n",
    "        tensorboard_writer.add_scalar('Test_Accuracy', test_accuracy, global_step=epoch)\n",
    "        tensorboard_writer.add_scalar('Test_Loss', test_average_loss, global_step=epoch)\n",
    "\n",
    "        # Aggregate and log confusion matrix\n",
    "        aggregated_confusion = confusion_matrix(all_test_labels, all_test_predicted)\n",
    "\n",
    "        # Confusion matrix\n",
    "        epsilon = 1e-8\n",
    "        df_cm = pd.DataFrame(aggregated_confusion / (np.sum(aggregated_confusion, axis=1)[:, None] + epsilon),\n",
    "                             index=[i for i in range(num_classes)],\n",
    "                             columns=[i for i in range(num_classes)])\n",
    "\n",
    "        # Save confusion matrix to Tensorbboard\n",
    "        figure = sn.heatmap(df_cm, annot=True).get_figure()\n",
    "        tensorboard_writer.add_figure(f'Aggregated Confusion Matrix - Epoch {epoch}', figure, global_step=epoch)\n",
    "\n",
    "        # Set the model back to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Plot histogram of uncertainties\n",
    "        class1_uncertainties = test_class_uncertainties[1]\n",
    "        plt.hist(class1_uncertainties, bins=50, alpha=0.5, color='blue', label='Class 1 Uncertainties')\n",
    "        plt.xlabel('Uncertainty')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Uncertainty Distribution for Class 1')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'ensemble_uncertainty_histogram_class1_epoch{epoch}_seed_{seed}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Save model (unique for each seed)\n",
    "    try:\n",
    "        print(f\"Saving final model for seed {seed} now...\")\n",
    "        torch.save(model.state_dict(), f'ensemble_multi_class_VGG2_case1_seed_{seed}.pth')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model for seed {seed}: {str(e)}\")\n",
    "\n",
    "    # Close the W&B run\n",
    "    wandb.finish()\n",
    "    \n",
    "    # Close file and reset stdout\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = sys.__stdout__  # Reset to default stdout\n",
    "\n",
    "    # Close the TensorBoard writer\n",
    "    tensorboard_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60785460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trainset, seed) in enumerate(zip(train_loaders, seeds)):\n",
    "    save_dataset(trainset.dataset, seed, f\"/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/undersampled_trainset_seed_{seed}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd9ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load undersampled training sets\n",
    "!ls -l /dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93quv/ensemble2_balanced_trainset_case1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74f1e2a",
   "metadata": {},
   "source": [
    "Here we create a new training dataset for every seed and we can modify the loop to generate a new dataset for each seed before retraining on that dataset. This way, the model is retrained on different subsets of the data for each seed, achieving the desired variation in the training data while keeping the test data constant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
